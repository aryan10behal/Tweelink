{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_results_cosine_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Statements"
      ],
      "metadata": {
        "id": "Ts-fOnw4P9WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "from itertools import islice\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from glob import glob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import math\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import operator\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpus')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import stats\n",
        "! pip install git+https://github.com/LIAAD/yake\n",
        "import yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBOv1bdeQBSj",
        "outputId": "cec086c0-3ec1-4f30-83e2-468a1b4420b6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
            "Collecting git+https://github.com/LIAAD/yake\n",
            "  Cloning https://github.com/LIAAD/yake to /tmp/pip-req-build-t3mvfz66\n",
            "  Running command git clone -q https://github.com/LIAAD/yake /tmp/pip-req-build-t3mvfz66\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (0.8.9)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (1.21.5)\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (1.5.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (2.6.3)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (0.9.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake==0.4.8) (2019.12.20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSb0ZbaNQHKn",
        "outputId": "7c8d74e4-a602-4941-e518-b5cac9bf68c9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TyRRoA3QJ-e",
        "outputId": "d86524e8-acc7-455c-8657-4b0c9120d10c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"/content/drive/MyDrive/Tweelink_Dataset/twitter_base_preprocessed.pkl\", \"rb\")\n",
        "df = pickle.load(file1)\n",
        "file1.close()"
      ],
      "metadata": {
        "id": "wZK40Dw9QLda"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "l18kFcfYTPnJ",
        "outputId": "d34de9d2-4747-4e2e-a326-1239f320be32"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               author id                 created_at geo country country_code  \\\n",
              "0           1952510090.0  2022-02-14 00:11:44+00:00                            \n",
              "1             20453105.0  2022-02-14 00:04:56+00:00                            \n",
              "2  1492660754998247424.0  2022-02-14 00:39:55+00:00                            \n",
              "3            117812637.0  2022-02-14 00:20:05+00:00                            \n",
              "4  1490044524604928000.0  2022-02-14 00:10:26+00:00                            \n",
              "\n",
              "  place_full_name place_name place_type                     id lang  ...  \\\n",
              "0                                        1493015060943454208.0   en  ...   \n",
              "1                                        1493013352938934272.0   en  ...   \n",
              "2                                        1493022155239534336.0   en  ...   \n",
              "3                                        1493017163485044736.0   en  ...   \n",
              "4                                        1493014734903382016.0   en  ...   \n",
              "\n",
              "                source                                              tweet  \\\n",
              "0  Twitter for Android  ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...   \n",
              "1  Twitter for Android  It's too bad these guys are afraid of needles,...   \n",
              "2  Twitter for Android  Cowboy dressed as #Furries now available at th...   \n",
              "3   Twitter for iPhone  We blocked these trucks from entering the dntn...   \n",
              "4   Twitter for iPhone  Krista is very pleased with how the @RCMPONT r...   \n",
              "\n",
              "                                            hashtags sensitive  \\\n",
              "0  CommonSenseGunLaws,GunControlNow,GunSafes,GunS...     False   \n",
              "1          ClownConvoy,FreeDumbConvoy,OttawaOccupied     False   \n",
              "2                    Furries,RamRanch,OttawaOccupied     False   \n",
              "3                           Riverside,OttawaOccupied     False   \n",
              "4  FluTruxKlanGoHome,OttawaOccupied,kkkonvoy,Otta...     False   \n",
              "\n",
              "                      urls context_text context_probability context_type  \\\n",
              "0  https://t.co/LjkEup24Dk                              0.0                \n",
              "1  https://t.co/MmFzuFjIDR                              0.0                \n",
              "2  https://t.co/GBuBCUtpXe                              0.0                \n",
              "3  https://t.co/KzLkBZvjgD                              0.0                \n",
              "4  https://t.co/kAm5KNugdA                              0.0                \n",
              "\n",
              "                                   Preprocessed_Data   Date_Only  \n",
              "0  [ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...  2022-02-14  \n",
              "1  [bad, guy, afraid, needle, twinrix, would, pre...  2022-02-14  \n",
              "2  [cowboy, dressed, furries, available, ramranch...  2022-02-14  \n",
              "3  [blocked, truck, entering, dntn, core, riversi...  2022-02-14  \n",
              "4  [krista, pleased, rcmpont, responded, maskless...  2022-02-14  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d4a6def-19f9-4abb-aa79-b453a618fe0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>geo</th>\n",
              "      <th>country</th>\n",
              "      <th>country_code</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_name</th>\n",
              "      <th>place_type</th>\n",
              "      <th>id</th>\n",
              "      <th>lang</th>\n",
              "      <th>...</th>\n",
              "      <th>source</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>sensitive</th>\n",
              "      <th>urls</th>\n",
              "      <th>context_text</th>\n",
              "      <th>context_probability</th>\n",
              "      <th>context_type</th>\n",
              "      <th>Preprocessed_Data</th>\n",
              "      <th>Date_Only</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1952510090.0</td>\n",
              "      <td>2022-02-14 00:11:44+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1493015060943454208.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...</td>\n",
              "      <td>CommonSenseGunLaws,GunControlNow,GunSafes,GunS...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/LjkEup24Dk</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...</td>\n",
              "      <td>2022-02-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20453105.0</td>\n",
              "      <td>2022-02-14 00:04:56+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1493013352938934272.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>It's too bad these guys are afraid of needles,...</td>\n",
              "      <td>ClownConvoy,FreeDumbConvoy,OttawaOccupied</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/MmFzuFjIDR</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[bad, guy, afraid, needle, twinrix, would, pre...</td>\n",
              "      <td>2022-02-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1492660754998247424.0</td>\n",
              "      <td>2022-02-14 00:39:55+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1493022155239534336.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>Cowboy dressed as #Furries now available at th...</td>\n",
              "      <td>Furries,RamRanch,OttawaOccupied</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/GBuBCUtpXe</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[cowboy, dressed, furries, available, ramranch...</td>\n",
              "      <td>2022-02-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>117812637.0</td>\n",
              "      <td>2022-02-14 00:20:05+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1493017163485044736.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>We blocked these trucks from entering the dntn...</td>\n",
              "      <td>Riverside,OttawaOccupied</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/KzLkBZvjgD</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[blocked, truck, entering, dntn, core, riversi...</td>\n",
              "      <td>2022-02-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1490044524604928000.0</td>\n",
              "      <td>2022-02-14 00:10:26+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1493014734903382016.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Krista is very pleased with how the @RCMPONT r...</td>\n",
              "      <td>FluTruxKlanGoHome,OttawaOccupied,kkkonvoy,Otta...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/kAm5KNugdA</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[krista, pleased, rcmpont, responded, maskless...</td>\n",
              "      <td>2022-02-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d4a6def-19f9-4abb-aa79-b453a618fe0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d4a6def-19f9-4abb-aa79-b453a618fe0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d4a6def-19f9-4abb-aa79-b453a618fe0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u_base_hashtag = input(\"Enter base hashtag: \")\n",
        "u_time = input(\"Enter time: \")\n",
        "u_location = input(\"Enter Location: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nvReo2xTQIG",
        "outputId": "5bc44da0-6e12-413a-fc89-0f55049e2a4f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter base hashtag: narendramodi\n",
            "Enter time: 2022-02-20\n",
            "Enter Location: india\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "tweet_query = []\n",
        "format = '%Y-%m-%d'\n",
        "u_present_date = datetime.datetime.strptime(u_time, format)\n",
        "u_prev_date = u_present_date - datetime.timedelta(days=1)\n",
        "u_next_date = u_present_date + datetime.timedelta(days=1)\n",
        "df_query = df.loc[df['hashtags'].str.contains(u_base_hashtag) & df['Date_Only'].isin([str(u_present_date.date()), str(u_prev_date.date()), str(u_next_date.date())])]"
      ],
      "metadata": {
        "id": "Ih0NQpCHTVVR"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_query.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "JPM7VJaBTf4b",
        "outputId": "3076f6c6-2b68-4a6b-cdc0-0c75e9b1f4c8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 author id                 created_at geo country  \\\n",
              "9279   1492152779082592258  2022-02-20 09:01:59+00:00               \n",
              "11494  1465937261271339013  2022-02-21 02:30:00+00:00               \n",
              "11746  1264485700361170944  2022-02-21 04:30:17+00:00               \n",
              "11748           3425906473  2022-02-21 04:38:27+00:00               \n",
              "11903           1253651582  2022-02-21 05:37:56+00:00               \n",
              "\n",
              "      country_code place_full_name place_name place_type                   id  \\\n",
              "9279                                                      1495322833022447616   \n",
              "11494                                                     1495586573504729090   \n",
              "11746                                                     1495616845256302595   \n",
              "11748                                                     1495618900482232320   \n",
              "11903                                                     1495633867365048320   \n",
              "\n",
              "      lang  ...               source  \\\n",
              "9279    en  ...  Twitter for Android   \n",
              "11494   en  ...      Twitter Web App   \n",
              "11746   en  ...        WordPress.com   \n",
              "11748   en  ...      Twitter Web App   \n",
              "11903   en  ...  Twitter for Android   \n",
              "\n",
              "                                                   tweet  \\\n",
              "9279   Click here to read our latest article on metav...   \n",
              "11494  Roads or Roller Coaster Rides? #TripuraDeserve...   \n",
              "11746  PM Narendra Modi Addresses People of Arunachal...   \n",
              "11748  'If Shiv Sena Forms A Third Front, Others Woul...   \n",
              "11903  @narendramodi Ji is the only person who is con...   \n",
              "\n",
              "                                                hashtags sensitive  \\\n",
              "9279   narendramodi,india,bjp,modi,amitshah,rahulgand...     False   \n",
              "11494  TripuraDeservesBetter,bjp,tripura,biplabdeb,Sh...     False   \n",
              "11746       arunachalpradesh,Modi,narendramodi,statehood     False   \n",
              "11748  bjp,india,narendramodi,modi,congress,amitshah,...     False   \n",
              "11903     Honor,courage,Pride,Modi,narendramodi,realhero     False   \n",
              "\n",
              "                                                  urls context_text  \\\n",
              "9279   https://t.co/V0pTteTYzF,https://t.co/mPuFtXt5Fs                \n",
              "11494                          https://t.co/aUFRfu1LBC                \n",
              "11746                          https://t.co/inPY7R1M9A                \n",
              "11748                          https://t.co/Rh5lLiiebQ                \n",
              "11903                          https://t.co/tNjghRlKXS                \n",
              "\n",
              "      context_probability context_type  \\\n",
              "9279                  0.0                \n",
              "11494                 0.0                \n",
              "11746                 0.0                \n",
              "11748                 0.0                \n",
              "11903                 0.0                \n",
              "\n",
              "                                       Preprocessed_Data   Date_Only  \n",
              "9279   [click, read, latest, article, metaverse, http...  2022-02-20  \n",
              "11494  [road, roller, coaster, ride, tripuradeservesb...  2022-02-21  \n",
              "11746  [pm, narendra, modi, address, people, arunacha...  2022-02-21  \n",
              "11748  [if, shiv, sena, form, third, front, others, w...  2022-02-21  \n",
              "11903  [narendramodi, ji, person, consistent, heart, ...  2022-02-21  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c011031-9f56-4964-9c45-1fcafcbf478d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>geo</th>\n",
              "      <th>country</th>\n",
              "      <th>country_code</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_name</th>\n",
              "      <th>place_type</th>\n",
              "      <th>id</th>\n",
              "      <th>lang</th>\n",
              "      <th>...</th>\n",
              "      <th>source</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>sensitive</th>\n",
              "      <th>urls</th>\n",
              "      <th>context_text</th>\n",
              "      <th>context_probability</th>\n",
              "      <th>context_type</th>\n",
              "      <th>Preprocessed_Data</th>\n",
              "      <th>Date_Only</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9279</th>\n",
              "      <td>1492152779082592258</td>\n",
              "      <td>2022-02-20 09:01:59+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495322833022447616</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>Click here to read our latest article on metav...</td>\n",
              "      <td>narendramodi,india,bjp,modi,amitshah,rahulgand...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/V0pTteTYzF,https://t.co/mPuFtXt5Fs</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[click, read, latest, article, metaverse, http...</td>\n",
              "      <td>2022-02-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11494</th>\n",
              "      <td>1465937261271339013</td>\n",
              "      <td>2022-02-21 02:30:00+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495586573504729090</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Roads or Roller Coaster Rides? #TripuraDeserve...</td>\n",
              "      <td>TripuraDeservesBetter,bjp,tripura,biplabdeb,Sh...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/aUFRfu1LBC</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[road, roller, coaster, ride, tripuradeservesb...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11746</th>\n",
              "      <td>1264485700361170944</td>\n",
              "      <td>2022-02-21 04:30:17+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495616845256302595</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>WordPress.com</td>\n",
              "      <td>PM Narendra Modi Addresses People of Arunachal...</td>\n",
              "      <td>arunachalpradesh,Modi,narendramodi,statehood</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/inPY7R1M9A</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[pm, narendra, modi, address, people, arunacha...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11748</th>\n",
              "      <td>3425906473</td>\n",
              "      <td>2022-02-21 04:38:27+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495618900482232320</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>'If Shiv Sena Forms A Third Front, Others Woul...</td>\n",
              "      <td>bjp,india,narendramodi,modi,congress,amitshah,...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/Rh5lLiiebQ</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[if, shiv, sena, form, third, front, others, w...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11903</th>\n",
              "      <td>1253651582</td>\n",
              "      <td>2022-02-21 05:37:56+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495633867365048320</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>@narendramodi Ji is the only person who is con...</td>\n",
              "      <td>Honor,courage,Pride,Modi,narendramodi,realhero</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/tNjghRlKXS</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[narendramodi, ji, person, consistent, heart, ...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c011031-9f56-4964-9c45-1fcafcbf478d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c011031-9f56-4964-9c45-1fcafcbf478d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c011031-9f56-4964-9c45-1fcafcbf478d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5w_SRasu2bfA",
        "outputId": "22a8200d-a76b-4bd0-8836-f47c29f5bf06"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   author id                 created_at geo country  \\\n",
              "9279     1492152779082592258  2022-02-20 09:01:59+00:00               \n",
              "11494    1465937261271339013  2022-02-21 02:30:00+00:00               \n",
              "11746    1264485700361170944  2022-02-21 04:30:17+00:00               \n",
              "11748             3425906473  2022-02-21 04:38:27+00:00               \n",
              "11903             1253651582  2022-02-21 05:37:56+00:00               \n",
              "12165    1072214525934489600  2022-02-21 07:09:19+00:00               \n",
              "12175             3425906473  2022-02-21 07:16:22+00:00               \n",
              "12181             3425906473  2022-02-21 07:27:34+00:00               \n",
              "12463             3425906473  2022-02-21 09:10:10+00:00               \n",
              "13762    1297831643743318016  2022-02-21 17:31:10+00:00               \n",
              "29771  1280086527284883456.0  2022-02-19 05:31:02+00:00               \n",
              "32934  1433046664978186240.0  2022-02-21 07:28:17+00:00               \n",
              "9936   1356720000000000000.0  2022-02-20 19:03:29+00:00               \n",
              "\n",
              "      country_code place_full_name place_name place_type  \\\n",
              "9279                                                       \n",
              "11494                                                      \n",
              "11746                                                      \n",
              "11748                                                      \n",
              "11903                                                      \n",
              "12165                                                      \n",
              "12175                                                      \n",
              "12181                                                      \n",
              "12463                                                      \n",
              "13762                                                      \n",
              "29771                                                      \n",
              "32934                                                      \n",
              "9936                                                       \n",
              "\n",
              "                          id lang  ...               source  \\\n",
              "9279     1495322833022447616   en  ...  Twitter for Android   \n",
              "11494    1495586573504729090   en  ...      Twitter Web App   \n",
              "11746    1495616845256302595   en  ...        WordPress.com   \n",
              "11748    1495618900482232320   en  ...      Twitter Web App   \n",
              "11903    1495633867365048320   en  ...  Twitter for Android   \n",
              "12165    1495656866176987136   en  ...      Twitter Web App   \n",
              "12175    1495658641374199810   en  ...      Twitter Web App   \n",
              "12181    1495661460563042305   en  ...      Twitter Web App   \n",
              "12463    1495687278882361349   en  ...      Twitter Web App   \n",
              "13762    1495813360494858243   en  ...  Twitter for Android   \n",
              "29771  1494907356878045184.0   en  ...              dlvr.it   \n",
              "32934  1495661640414789632.0   en  ...      Twitter Web App   \n",
              "9936   1495470000000000000.0   en  ...      Twitter Web App   \n",
              "\n",
              "                                                   tweet  \\\n",
              "9279   Click here to read our latest article on metav...   \n",
              "11494  Roads or Roller Coaster Rides? #TripuraDeserve...   \n",
              "11746  PM Narendra Modi Addresses People of Arunachal...   \n",
              "11748  'If Shiv Sena Forms A Third Front, Others Woul...   \n",
              "11903  @narendramodi Ji is the only person who is con...   \n",
              "12165  After he relinquishes power he will get employ...   \n",
              "12175  Rajnath Singh Condemns Rahul Gandhi's Chinese ...   \n",
              "12181  Priyanka Gandhi Slams Akhilesh And Mayawati, D...   \n",
              "12463  Shivamogga: Following The Death Of A Bajrang D...   \n",
              "13762  Asiaâs biggest Bio-CNG plant at Madhya Prade...   \n",
              "29771  'During Emergency, I used to wear a Sikh turba...   \n",
              "32934  Queen Elizabeth Tested Positive For Covid-19: ...   \n",
              "9936   UP: Modi recalls Ahmedabad blasts, says some p...   \n",
              "\n",
              "                                                hashtags sensitive  \\\n",
              "9279   narendramodi,india,bjp,modi,amitshah,rahulgand...     False   \n",
              "11494  TripuraDeservesBetter,bjp,tripura,biplabdeb,Sh...     False   \n",
              "11746       arunachalpradesh,Modi,narendramodi,statehood     False   \n",
              "11748  bjp,india,narendramodi,modi,congress,amitshah,...     False   \n",
              "11903     Honor,courage,Pride,Modi,narendramodi,realhero     False   \n",
              "12165  Boycott_Modi,à¤­à¤¾à¤à¤ªà¤¾_à¤à¤¾_à¤°à¤¹à¥_...     False   \n",
              "12175  rahulgandhi,congress,bjp,narendramodi,india,mo...     False   \n",
              "12181  priyankagandhi,rahulgandhi,congress,soniagandh...     False   \n",
              "12463  bajrangdal,rss,bjp,hindu,hinduism,india,hindut...     False   \n",
              "13762  asia,bio,gas,nature,environment,precautions,de...     False   \n",
              "29771  narendramodi,punjabelections2022,assemblyelect...     False   \n",
              "32934  QueenElizabeth,thebuckinghampalace,ElizabethII...     False   \n",
              "9936   UPElection2022,upassemblyelection2022,UPAssemb...     False   \n",
              "\n",
              "                                                  urls context_text  \\\n",
              "9279   https://t.co/V0pTteTYzF,https://t.co/mPuFtXt5Fs                \n",
              "11494                          https://t.co/aUFRfu1LBC                \n",
              "11746                          https://t.co/inPY7R1M9A                \n",
              "11748                          https://t.co/Rh5lLiiebQ                \n",
              "11903                          https://t.co/tNjghRlKXS                \n",
              "12165                          https://t.co/07dVqirctY                \n",
              "12175                          https://t.co/isQrLQqVrz                \n",
              "12181                          https://t.co/oMh0rKm9vE                \n",
              "12463                          https://t.co/TW4D3wGgb1                \n",
              "13762                          https://t.co/wXwAWjJAGe                \n",
              "29771                          https://t.co/6dHAlWogDw                \n",
              "32934  https://t.co/sFUOJFIjXT,https://t.co/wOPdETsvh8                \n",
              "9936                           https://t.co/0tSCOKNW90                \n",
              "\n",
              "      context_probability context_type  \\\n",
              "9279                  0.0                \n",
              "11494                 0.0                \n",
              "11746                 0.0                \n",
              "11748                 0.0                \n",
              "11903                 0.0                \n",
              "12165                 0.0                \n",
              "12175                 0.0                \n",
              "12181                 0.0                \n",
              "12463                 0.0                \n",
              "13762                 0.0                \n",
              "29771                 0.0                \n",
              "32934                 0.0                \n",
              "9936                  0.0                \n",
              "\n",
              "                                       Preprocessed_Data   Date_Only  \n",
              "9279   [click, read, latest, article, metaverse, http...  2022-02-20  \n",
              "11494  [road, roller, coaster, ride, tripuradeservesb...  2022-02-21  \n",
              "11746  [pm, narendra, modi, address, people, arunacha...  2022-02-21  \n",
              "11748  [if, shiv, sena, form, third, front, others, w...  2022-02-21  \n",
              "11903  [narendramodi, ji, person, consistent, heart, ...  2022-02-21  \n",
              "12165  [relinquishes, power, get, employment, bollywo...  2022-02-21  \n",
              "12175  [rajnath, singh, condemns, rahul, gandhi, s, c...  2022-02-21  \n",
              "12181  [priyanka, gandhi, slam, akhilesh, mayawati, d...  2022-02-21  \n",
              "12463  [shivamogga, following, death, bajrang, dal, w...  2022-02-21  \n",
              "13762  [asiaâs, biggest, biocng, plant, madhya, pra...  2022-02-21  \n",
              "29771  [during, emergency, used, wear, sikh, turban, ...  2022-02-19  \n",
              "32934  [queen, elizabeth, tested, positive, covid19, ...  2022-02-21  \n",
              "9936   [modi, recall, ahmedabad, blast, say, party, s...  2022-02-20  \n",
              "\n",
              "[13 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-925b0e86-4614-4e7b-9b16-03ee54c1468e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>geo</th>\n",
              "      <th>country</th>\n",
              "      <th>country_code</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_name</th>\n",
              "      <th>place_type</th>\n",
              "      <th>id</th>\n",
              "      <th>lang</th>\n",
              "      <th>...</th>\n",
              "      <th>source</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>sensitive</th>\n",
              "      <th>urls</th>\n",
              "      <th>context_text</th>\n",
              "      <th>context_probability</th>\n",
              "      <th>context_type</th>\n",
              "      <th>Preprocessed_Data</th>\n",
              "      <th>Date_Only</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9279</th>\n",
              "      <td>1492152779082592258</td>\n",
              "      <td>2022-02-20 09:01:59+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495322833022447616</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>Click here to read our latest article on metav...</td>\n",
              "      <td>narendramodi,india,bjp,modi,amitshah,rahulgand...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/V0pTteTYzF,https://t.co/mPuFtXt5Fs</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[click, read, latest, article, metaverse, http...</td>\n",
              "      <td>2022-02-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11494</th>\n",
              "      <td>1465937261271339013</td>\n",
              "      <td>2022-02-21 02:30:00+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495586573504729090</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Roads or Roller Coaster Rides? #TripuraDeserve...</td>\n",
              "      <td>TripuraDeservesBetter,bjp,tripura,biplabdeb,Sh...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/aUFRfu1LBC</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[road, roller, coaster, ride, tripuradeservesb...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11746</th>\n",
              "      <td>1264485700361170944</td>\n",
              "      <td>2022-02-21 04:30:17+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495616845256302595</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>WordPress.com</td>\n",
              "      <td>PM Narendra Modi Addresses People of Arunachal...</td>\n",
              "      <td>arunachalpradesh,Modi,narendramodi,statehood</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/inPY7R1M9A</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[pm, narendra, modi, address, people, arunacha...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11748</th>\n",
              "      <td>3425906473</td>\n",
              "      <td>2022-02-21 04:38:27+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495618900482232320</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>'If Shiv Sena Forms A Third Front, Others Woul...</td>\n",
              "      <td>bjp,india,narendramodi,modi,congress,amitshah,...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/Rh5lLiiebQ</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[if, shiv, sena, form, third, front, others, w...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11903</th>\n",
              "      <td>1253651582</td>\n",
              "      <td>2022-02-21 05:37:56+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495633867365048320</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>@narendramodi Ji is the only person who is con...</td>\n",
              "      <td>Honor,courage,Pride,Modi,narendramodi,realhero</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/tNjghRlKXS</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[narendramodi, ji, person, consistent, heart, ...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12165</th>\n",
              "      <td>1072214525934489600</td>\n",
              "      <td>2022-02-21 07:09:19+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495656866176987136</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>After he relinquishes power he will get employ...</td>\n",
              "      <td>Boycott_Modi,à¤­à¤¾à¤à¤ªà¤¾_à¤à¤¾_à¤°à¤¹à¥_...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/07dVqirctY</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[relinquishes, power, get, employment, bollywo...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12175</th>\n",
              "      <td>3425906473</td>\n",
              "      <td>2022-02-21 07:16:22+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495658641374199810</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Rajnath Singh Condemns Rahul Gandhi's Chinese ...</td>\n",
              "      <td>rahulgandhi,congress,bjp,narendramodi,india,mo...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/isQrLQqVrz</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[rajnath, singh, condemns, rahul, gandhi, s, c...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12181</th>\n",
              "      <td>3425906473</td>\n",
              "      <td>2022-02-21 07:27:34+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495661460563042305</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Priyanka Gandhi Slams Akhilesh And Mayawati, D...</td>\n",
              "      <td>priyankagandhi,rahulgandhi,congress,soniagandh...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/oMh0rKm9vE</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[priyanka, gandhi, slam, akhilesh, mayawati, d...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12463</th>\n",
              "      <td>3425906473</td>\n",
              "      <td>2022-02-21 09:10:10+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495687278882361349</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Shivamogga: Following The Death Of A Bajrang D...</td>\n",
              "      <td>bajrangdal,rss,bjp,hindu,hinduism,india,hindut...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/TW4D3wGgb1</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[shivamogga, following, death, bajrang, dal, w...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13762</th>\n",
              "      <td>1297831643743318016</td>\n",
              "      <td>2022-02-21 17:31:10+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495813360494858243</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>Asiaâs biggest Bio-CNG plant at Madhya Prade...</td>\n",
              "      <td>asia,bio,gas,nature,environment,precautions,de...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/wXwAWjJAGe</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[asiaâs, biggest, biocng, plant, madhya, pra...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29771</th>\n",
              "      <td>1280086527284883456.0</td>\n",
              "      <td>2022-02-19 05:31:02+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1494907356878045184.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>dlvr.it</td>\n",
              "      <td>'During Emergency, I used to wear a Sikh turba...</td>\n",
              "      <td>narendramodi,punjabelections2022,assemblyelect...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/6dHAlWogDw</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[during, emergency, used, wear, sikh, turban, ...</td>\n",
              "      <td>2022-02-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32934</th>\n",
              "      <td>1433046664978186240.0</td>\n",
              "      <td>2022-02-21 07:28:17+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495661640414789632.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Queen Elizabeth Tested Positive For Covid-19: ...</td>\n",
              "      <td>QueenElizabeth,thebuckinghampalace,ElizabethII...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/sFUOJFIjXT,https://t.co/wOPdETsvh8</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[queen, elizabeth, tested, positive, covid19, ...</td>\n",
              "      <td>2022-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9936</th>\n",
              "      <td>1356720000000000000.0</td>\n",
              "      <td>2022-02-20 19:03:29+00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1495470000000000000.0</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>UP: Modi recalls Ahmedabad blasts, says some p...</td>\n",
              "      <td>UPElection2022,upassemblyelection2022,UPAssemb...</td>\n",
              "      <td>False</td>\n",
              "      <td>https://t.co/0tSCOKNW90</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[modi, recall, ahmedabad, blast, say, party, s...</td>\n",
              "      <td>2022-02-20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-925b0e86-4614-4e7b-9b16-03ee54c1468e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-925b0e86-4614-4e7b-9b16-03ee54c1468e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-925b0e86-4614-4e7b-9b16-03ee54c1468e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_extractor(dataset):\n",
        "  preprocessed_vocabulary = dict()\n",
        "\n",
        "  #Converting to lowercase\n",
        "  def to_lower_case(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "  def remove_at_word(text):\n",
        "    data = text.split()\n",
        "    data = [d for d in data if d[0]!='@']\n",
        "    text = ' '.join(data)\n",
        "    return text\n",
        "\n",
        "  def remove_hashtag(text):\n",
        "    data = text.split()\n",
        "    data = [d if (d[0]!='#' or len(d) == 1) else d[1:] for d in data]\n",
        "    data = [d for d in data if d[0]!='#']\n",
        "    text = ' '.join(data)\n",
        "    return text\n",
        "\n",
        "  def remove_URL(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r'bit.ly\\S+', '', text, flags=re.MULTILINE)\n",
        "    return text\n",
        "\n",
        "  #Removing stopwords\n",
        "  def remove_stopwords(text):\n",
        "    stopword = stopwords.words('english')\n",
        "    new_list = [x for x in text.split() if x not in stopword]\n",
        "    return ' '.join(new_list)\n",
        "\n",
        "  #Removing punctuations\n",
        "  def remove_punctuations(text):\n",
        "    punctuations = '''!()-[|]`{};:'\"\\,<>./?@#$=+%^&*_~'''\n",
        "    new_list = ['' if x in punctuations else x for x in text.split()]\n",
        "    new_list_final = []\n",
        "    for token in new_list:\n",
        "      new_token=\"\"\n",
        "      for char in token:\n",
        "        if(char not in punctuations):\n",
        "          new_token+=char\n",
        "      if(len(new_token)!=0):\n",
        "        new_list_final.append(new_token)\n",
        "    return ' '.join(new_list_final)\n",
        "\n",
        "  #Tokenization\n",
        "  def tokenization(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "  def pre_process(text):\n",
        "    text = to_lower_case(text)\n",
        "    text = remove_at_word(text)\n",
        "    text = remove_hashtag(text)\n",
        "    text = remove_URL(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = remove_punctuations(text)\n",
        "    text = tokenization(text)\n",
        "    for token in text:\n",
        "      if token in preprocessed_vocabulary.keys():\n",
        "        preprocessed_vocabulary[token] += 1\n",
        "      else:\n",
        "        preprocessed_vocabulary[token] = 1\n",
        "    return text\n",
        "  \n",
        "  preprocessed_data = [pre_process(text) for text in dataset]\n",
        "\n",
        "  #print(preprocessed_vocabulary)\n",
        "\n",
        "  AOF_coefficient = sum(preprocessed_vocabulary.values())/len(preprocessed_vocabulary)\n",
        "  vocabulary = {token.strip():preprocessed_vocabulary[token] for token in preprocessed_vocabulary.keys() if preprocessed_vocabulary[token] > AOF_coefficient and len(token.strip())}\n",
        "\n",
        "  #print(vocabulary)\n",
        "\n",
        "  final_tokens_per_tweet = []\n",
        "  for data in preprocessed_data:\n",
        "    final_tokens_per_tweet.append([token for token in data if token in vocabulary.keys()])\n",
        "\n",
        "  #print(preprocessed_data)\n",
        "  #print(final_tokens_per_tweet)\n",
        "\n",
        "  word2id = dict()\n",
        "  id2word = dict()\n",
        "  vocabulary_size = len(vocabulary)\n",
        "  count = 0\n",
        "  for token in vocabulary.keys():\n",
        "    word2id[token] = count\n",
        "    id2word[count] = token\n",
        "    count += 1\n",
        "\n",
        "  #print(word2id)\n",
        "  #print(id2word)\n",
        "\n",
        "  directed_graph_adjacency_matrix = np.zeros((vocabulary_size, vocabulary_size))\n",
        "  edge_weight_matrix = np.zeros((vocabulary_size, vocabulary_size))\n",
        "  first_frequency = dict()\n",
        "  last_frequency = dict()\n",
        "  term_frequency = vocabulary\n",
        "  strength = dict()\n",
        "  degree = dict()\n",
        "  selective_centraility = dict()\n",
        "\n",
        "\n",
        "  for tweet in final_tokens_per_tweet:\n",
        "\n",
        "    if tweet[0] in first_frequency.keys():\n",
        "      first_frequency[tweet[0]] += 1\n",
        "    else:\n",
        "      first_frequency[tweet[0]] = 1\n",
        "\n",
        "    if tweet[-1] in last_frequency.keys():\n",
        "      last_frequency[tweet[-1]] += 1\n",
        "    else:\n",
        "      last_frequency[tweet[-1]] = 1\n",
        "    \n",
        "\n",
        "\n",
        "    for i in range(len(tweet)-1):\n",
        "      if tweet[i] == tweet[i+1]:\n",
        "        continue\n",
        "      x = word2id[tweet[i]]\n",
        "      y = word2id[tweet[i+1]]\n",
        "      directed_graph_adjacency_matrix[x][y] += 1\n",
        "\n",
        "  for tweet in final_tokens_per_tweet:\n",
        "    for i in range(len(tweet)-1):\n",
        "\n",
        "\n",
        "      if tweet[i] == tweet[i+1]:\n",
        "        continue\n",
        "      x = word2id[tweet[i]]\n",
        "      y = word2id[tweet[i+1]]\n",
        "\n",
        "    # Updating degree..\n",
        "      if tweet[i] in degree.keys():\n",
        "        degree[tweet[i]] += 1\n",
        "      else:\n",
        "        degree[tweet[i]] = 1\n",
        "        \n",
        "      if tweet[i+1] in degree.keys():\n",
        "        degree[tweet[i+1]] += 1\n",
        "      else:\n",
        "        degree[tweet[i+1]] = 1\n",
        "\n",
        "      edge_weight_matrix[x][y] = directed_graph_adjacency_matrix[x][y]/(vocabulary[tweet[i]] + vocabulary[tweet[i+1]] - directed_graph_adjacency_matrix[x][y])\n",
        "\n",
        "      if tweet[i] in strength.keys():\n",
        "        strength[tweet[i]] += edge_weight_matrix[x][y]\n",
        "      else:\n",
        "        strength[tweet[i]] = edge_weight_matrix[x][y]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  first_frequency = {token:(first_frequency[token]/vocabulary[token] if token in first_frequency else 0) for token in vocabulary.keys()}\n",
        "  last_frequency = {token:(last_frequency[token]/vocabulary[token] if token in last_frequency else 0) for token in vocabulary.keys()}\n",
        "  degree = {token:(degree[token] if token in degree else 0) for token in vocabulary.keys()}\n",
        "  strength = {token:(strength[token] if token in strength else 0) for token in vocabulary.keys()}\n",
        "  selective_centraility = {token:(strength[token]/degree[token] if degree[token]!=0 else 0) for token in vocabulary.keys()}\n",
        "\n",
        "  #print(degree)\n",
        "  #print(vocabulary)\n",
        "\n",
        "  maxdegree = max(degree.items(), key=lambda x: x[1])[1]\n",
        "  max_degree_nodes_with_freq = {key:term_frequency[key] for key in degree.keys() if degree[key] == maxdegree}\n",
        "  maxfreq = max(max_degree_nodes_with_freq.items(), key=lambda x: x[1])[1]\n",
        "  central_node_name = [key for key in max_degree_nodes_with_freq.keys() if max_degree_nodes_with_freq[key] == maxfreq][0]\n",
        "  #print(\"central node: \", central_node_name)\n",
        "\n",
        "  # bfs\n",
        "  distance_from_central_node = dict()\n",
        "  central_node_id = word2id[central_node_name]\n",
        "  q = [(central_node_id, 0)]\n",
        "\n",
        "  # Set source as visited\n",
        "  distance_from_central_node[central_node_name] = 0\n",
        "\n",
        "  while q:\n",
        "      vis = q[0]\n",
        "      # Print current node\n",
        "      #print(id2word[vis[0]], vis[1])\n",
        "      q.pop(0)\n",
        "        \n",
        "      # For every adjacent vertex to\n",
        "      # the current vertex\n",
        "      for i in range(len(directed_graph_adjacency_matrix[vis[0]])):\n",
        "          if (directed_graph_adjacency_matrix[vis[0]][i] == 1 and (id2word[i] not in distance_from_central_node.keys())):\n",
        "              # Push the adjacent node\n",
        "              # in the queue\n",
        "              q.append((i, vis[1]+1))\n",
        "              distance_from_central_node[id2word[i]] = vis[1]+1\n",
        "\n",
        "  #print(distance_from_central_node)\n",
        "  inverse_distance_from_central_node = {token:(1/distance_from_central_node[token] if token in distance_from_central_node and token != central_node_name else 0) for token in vocabulary.keys()}\n",
        "  inverse_distance_from_central_node[central_node_name] = 1.0\n",
        "  #print(inverse_distance_from_central_node)\n",
        "\n",
        "  neighbour_importance = dict()\n",
        "\n",
        "  for i in range(len(directed_graph_adjacency_matrix)):\n",
        "    neighbours = set()\n",
        "\n",
        "    # traversing outgoing edges\n",
        "    for j in range(len(directed_graph_adjacency_matrix)):\n",
        "      if i == j:\n",
        "        continue\n",
        "      if directed_graph_adjacency_matrix[i][j] > 0:\n",
        "        neighbours.add(j)\n",
        "    for j in range(len(directed_graph_adjacency_matrix)):\n",
        "      if i == j:\n",
        "        continue\n",
        "      if directed_graph_adjacency_matrix[j][i] > 0:\n",
        "          neighbours.add(j)\n",
        "    if len(neighbours) != 0:\n",
        "      neighbour_importance[id2word[i]] = sum([strength[id2word[j]] for j in neighbours])/len(neighbours)\n",
        "    else:\n",
        "      neighbour_importance[id2word[i]] = 0\n",
        "      \n",
        "  #print(neighbour_importance)\n",
        "\n",
        "  unnormalized_node_weight = {node: (first_frequency[node] + last_frequency[node] + term_frequency[node] + selective_centraility[node] + inverse_distance_from_central_node[node] + neighbour_importance[node]) for node in vocabulary.keys()}\n",
        "  max_node_weight = max(unnormalized_node_weight.items(), key=lambda x: x[1])[1]\n",
        "  min_node_weight = min(unnormalized_node_weight.items(), key=lambda x: x[1])[1]\n",
        "  #print(\"max node weight: \", max_node_weight, \"min node weight: \", min_node_weight)\n",
        "  normalized_node_weight = {node: ((unnormalized_node_weight[node] - min_node_weight)/(max_node_weight - min_node_weight) if max_node_weight != min_node_weight else unnormalized_node_weight[node]) for node in unnormalized_node_weight.keys()}\n",
        "  #print(\"Unnormalized score: \", unnormalized_node_weight)\n",
        "  #print(\"Normalized score: \", normalized_node_weight)\n",
        "\n",
        "  damping_factor = 0.85\n",
        "  relevance_of_node = {node: np.random.uniform(0,1,1)[0] for node in vocabulary.keys()}\n",
        "  threshold = 0.000000001\n",
        "\n",
        "\n",
        "  #print(relevance_of_node)\n",
        "\n",
        "  count = 0\n",
        "  while True:\n",
        "    count += 1\n",
        "    current_relevance_of_node = dict()\n",
        "    for node in vocabulary.keys():\n",
        "      outer_sum = 0\n",
        "      node_idx = word2id[node]\n",
        "      for j in range(len(directed_graph_adjacency_matrix)):\n",
        "        if j == node_idx:\n",
        "          continue\n",
        "        if directed_graph_adjacency_matrix[j][node_idx] > 0:\n",
        "          den_sum = 0\n",
        "          for k in range(len(directed_graph_adjacency_matrix)):\n",
        "            if k == j:\n",
        "              continue\n",
        "            den_sum += directed_graph_adjacency_matrix[j][k]\n",
        "          outer_sum += ((directed_graph_adjacency_matrix[j][node_idx]/den_sum) * relevance_of_node[id2word[j]])\n",
        "      current_relevance_of_node[node] = (1-damping_factor)*normalized_node_weight[node] + damping_factor*normalized_node_weight[node]*outer_sum\n",
        "    \n",
        "\n",
        "    # checking convergence..\n",
        "    sq_error = sum([(current_relevance_of_node[node] - relevance_of_node[node])**2 for node in vocabulary.keys()])\n",
        "    relevance_of_node = current_relevance_of_node\n",
        "    if sq_error < threshold:\n",
        "      break\n",
        "\n",
        "  #print(relevance_of_node)\n",
        "  #print(count)\n",
        "\n",
        "  degree_centrality  = {node: 0 for node in vocabulary.keys()}\n",
        "\n",
        "  if len(directed_graph_adjacency_matrix) > 1:\n",
        "    for i in range(len(directed_graph_adjacency_matrix)):\n",
        "      count = 0\n",
        "      for j in range(len(directed_graph_adjacency_matrix)):\n",
        "        if i == j:\n",
        "          continue\n",
        "        if directed_graph_adjacency_matrix[j][i] > 0:\n",
        "          count += 1\n",
        "      degree_centrality[id2word[i]] = count / (len(directed_graph_adjacency_matrix)-1)\n",
        "\n",
        "  #print(degree_centrality)\n",
        "\n",
        "  final_keyword_rank = [{'node': node, 'NE_rank': relevance_of_node[node], 'Degree': degree_centrality[node]} for node in vocabulary.keys()]\n",
        "\n",
        "  #print(\"-----------\")\n",
        "  final_keyword_rank = sorted(final_keyword_rank, key = lambda i: (i['NE_rank'], i['Degree']), reverse = True)\n",
        "\n",
        "  final_keywords = [keyword['node'] for keyword in final_keyword_rank]\n",
        "\n",
        "  return final_keywords"
      ],
      "metadata": {
        "id": "FVkoAcGos6SQ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in df_query['Preprocessed_Data']:\n",
        "  tweet_query.extend(tweet)"
      ],
      "metadata": {
        "id": "vgHmoH0ST3K0"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmUpvWHIT3lY",
        "outputId": "58008f0d-79f1-48e9-eabf-3bdc4f08a420"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['click',\n",
              " 'read',\n",
              " 'latest',\n",
              " 'article',\n",
              " 'metaverse',\n",
              " 'http',\n",
              " 'tcov0pttetyzf',\n",
              " 'narendramodi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'modi',\n",
              " 'amitshah',\n",
              " 'rahulgandhi',\n",
              " 'yogiadityanath',\n",
              " 'hindu',\n",
              " 'congress',\n",
              " 'indian',\n",
              " 'delhi',\n",
              " 'r',\n",
              " 'namo',\n",
              " 'politics',\n",
              " 'instagram',\n",
              " 'hinduism',\n",
              " 'covid',\n",
              " 'mumbai',\n",
              " 'indianpolitics',\n",
              " 'indianarmy',\n",
              " 'news',\n",
              " 'bhfyp',\n",
              " 'http',\n",
              " 'tcompuftxt5fs',\n",
              " 'narendramodi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'modi',\n",
              " 'amitshah',\n",
              " 'rahulgandhi',\n",
              " 'yogiadityanath',\n",
              " 'hindu',\n",
              " 'congress',\n",
              " 'indian',\n",
              " 'delhi',\n",
              " 'r',\n",
              " 'namo',\n",
              " 'politics',\n",
              " 'instagram',\n",
              " 'hinduism',\n",
              " 'covid',\n",
              " 'mumbai',\n",
              " 'indianpolitics',\n",
              " 'indianarmy',\n",
              " 'news',\n",
              " 'bhfyp',\n",
              " 'road',\n",
              " 'roller',\n",
              " 'coaster',\n",
              " 'ride',\n",
              " 'tripuradeservesbetter',\n",
              " 'bjp',\n",
              " 'tripura',\n",
              " 'biplabdeb',\n",
              " 'shameonbjp',\n",
              " 'fraud',\n",
              " 'india',\n",
              " 'politics',\n",
              " 'novotetobjp',\n",
              " 'bjphatao',\n",
              " 'bjphataodeshbachao',\n",
              " 'cm',\n",
              " 'news',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'http',\n",
              " 'tcoaufrfu1lbc',\n",
              " 'tripuradeservesbetter',\n",
              " 'bjp',\n",
              " 'tripura',\n",
              " 'biplabdeb',\n",
              " 'shameonbjp',\n",
              " 'fraud',\n",
              " 'india',\n",
              " 'politics',\n",
              " 'novotetobjp',\n",
              " 'bjphatao',\n",
              " 'bjphataodeshbachao',\n",
              " 'cm',\n",
              " 'news',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'pm',\n",
              " 'narendra',\n",
              " 'modi',\n",
              " 'address',\n",
              " 'people',\n",
              " 'arunachal',\n",
              " 'pradesh',\n",
              " '36th',\n",
              " 'statehood',\n",
              " 'day',\n",
              " 'praised',\n",
              " 'strengthening',\n",
              " 'identity',\n",
              " 'land',\n",
              " 'rising',\n",
              " 'sun',\n",
              " 'past',\n",
              " '50',\n",
              " 'year',\n",
              " 'arunachalpradesh',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'statehood',\n",
              " 'http',\n",
              " 'tcoinpy7r1m9a',\n",
              " 'arunachalpradesh',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'statehood',\n",
              " 'if',\n",
              " 'shiv',\n",
              " 'sena',\n",
              " 'form',\n",
              " 'third',\n",
              " 'front',\n",
              " 'others',\n",
              " 'would',\n",
              " 'follow',\n",
              " 'suit',\n",
              " 'ramdas',\n",
              " 'athawale',\n",
              " 'kcr',\n",
              " 's',\n",
              " 'antibjp',\n",
              " 'rally',\n",
              " 'mumbai',\n",
              " 'http',\n",
              " 'tcorh5lliiebq',\n",
              " 'bjp',\n",
              " 'india',\n",
              " 'narendramodi',\n",
              " 'modi',\n",
              " 'congress',\n",
              " 'amitshah',\n",
              " 'hindu',\n",
              " 'politics',\n",
              " 'rahulgandhi',\n",
              " 'yogiadityanath',\n",
              " 'news',\n",
              " 'trendingnews',\n",
              " 'latestnews',\n",
              " 'todaynews',\n",
              " 'bjp',\n",
              " 'india',\n",
              " 'narendramodi',\n",
              " 'modi',\n",
              " 'congress',\n",
              " 'amitshah',\n",
              " 'hindu',\n",
              " 'politics',\n",
              " 'rahulgandhi',\n",
              " 'yogiadityanath',\n",
              " 'news',\n",
              " 'trendingnews',\n",
              " 'latestnews',\n",
              " 'todaynews',\n",
              " 'narendramodi',\n",
              " 'ji',\n",
              " 'person',\n",
              " 'consistent',\n",
              " 'heart',\n",
              " 'people',\n",
              " 'prime',\n",
              " 'minister',\n",
              " 'modi',\n",
              " 'ji',\n",
              " 'honor',\n",
              " 'prime',\n",
              " 'minister',\n",
              " 'modi',\n",
              " 'ji',\n",
              " 'courage',\n",
              " 'prime',\n",
              " 'minister',\n",
              " 'modi',\n",
              " 'ji',\n",
              " 'pride',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'realhero',\n",
              " 'http',\n",
              " 'tcotnjghrlkxs',\n",
              " 'honor',\n",
              " 'courage',\n",
              " 'pride',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'realhero',\n",
              " 'relinquishes',\n",
              " 'power',\n",
              " 'get',\n",
              " 'employment',\n",
              " 'bollywood',\n",
              " 'ð\\x9f\\x98\\x83ð\\x9f\\x98\\x83ð\\x9f\\x98\\x83',\n",
              " 'boycottmodi',\n",
              " 'à¤\\xadà¤¾à¤\\x9cà¤ªà¤¾à¤\\x9cà¤¾à¤°à¤¹à¥\\x80à¤¹à¥\\x88',\n",
              " 'modi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'narendramodi',\n",
              " 'congress',\n",
              " 'modilies',\n",
              " 'modifailedindia',\n",
              " 'modimadedisaster',\n",
              " 'http',\n",
              " 'tco07dvqircty',\n",
              " 'boycottmodi',\n",
              " 'à¤\\xadà¤¾à¤\\x9cà¤ªà¤¾à¤\\x9cà¤¾à¤°à¤¹à¥\\x80à¤¹à¥\\x88',\n",
              " 'modi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'narendramodi',\n",
              " 'congress',\n",
              " 'modilies',\n",
              " 'modifailedindia',\n",
              " 'modimadedisaster',\n",
              " 'rajnath',\n",
              " 'singh',\n",
              " 'condemns',\n",
              " 'rahul',\n",
              " 'gandhi',\n",
              " 's',\n",
              " 'chinese',\n",
              " 'incursion',\n",
              " 'claim',\n",
              " 'declaring',\n",
              " 'he',\n",
              " 'casting',\n",
              " 'aspersion',\n",
              " 'valour',\n",
              " 'india',\n",
              " 's',\n",
              " 'soldier',\n",
              " 'http',\n",
              " 'tcoisqrlqqvrz',\n",
              " 'rahulgandhi',\n",
              " 'congress',\n",
              " 'bjp',\n",
              " 'narendramodi',\n",
              " 'india',\n",
              " 'modi',\n",
              " 'amitshah',\n",
              " 'politics',\n",
              " 'indianpolitics',\n",
              " 'priyankagandhi',\n",
              " 'rahulgandhi',\n",
              " 'congress',\n",
              " 'bjp',\n",
              " 'narendramodi',\n",
              " 'india',\n",
              " 'modi',\n",
              " 'amitshah',\n",
              " 'politics',\n",
              " 'indianpolitics',\n",
              " 'priyankagandhi',\n",
              " 'priyanka',\n",
              " 'gandhi',\n",
              " 'slam',\n",
              " 'akhilesh',\n",
              " 'mayawati',\n",
              " 'declaring',\n",
              " 'politics',\n",
              " 'done',\n",
              " 'home',\n",
              " 'twitter',\n",
              " 'http',\n",
              " 'tcoomh0rkm9ve',\n",
              " 'priyankagandhi',\n",
              " 'rahulgandhi',\n",
              " 'congress',\n",
              " 'soniagandhi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'modi',\n",
              " 'inc',\n",
              " 'narendramodi',\n",
              " 'amitshah',\n",
              " 'indiannationalcongress',\n",
              " 'indianpolitics',\n",
              " 'delhi',\n",
              " 'priyankagandhi',\n",
              " 'rahulgandhi',\n",
              " 'congress',\n",
              " 'soniagandhi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'modi',\n",
              " 'inc',\n",
              " 'narendramodi',\n",
              " 'amitshah',\n",
              " 'indiannationalcongress',\n",
              " 'indianpolitics',\n",
              " 'delhi',\n",
              " 'shivamogga',\n",
              " 'following',\n",
              " 'death',\n",
              " 'bajrang',\n",
              " 'dal',\n",
              " 'worker',\n",
              " 'security',\n",
              " 'strengthened',\n",
              " 'school',\n",
              " 'closed',\n",
              " 'http',\n",
              " 'tcotw4d3wggb1',\n",
              " 'bajrangdal',\n",
              " 'r',\n",
              " 'bjp',\n",
              " 'hindu',\n",
              " 'hinduism',\n",
              " 'india',\n",
              " 'hindutva',\n",
              " 'narendramodi',\n",
              " 'jaishreeram',\n",
              " 'modi',\n",
              " 'hindustan',\n",
              " 'sanatandharma',\n",
              " 'vhp',\n",
              " 'bhagwa',\n",
              " 'bajrangdal',\n",
              " 'r',\n",
              " 'bjp',\n",
              " 'hindu',\n",
              " 'hinduism',\n",
              " 'india',\n",
              " 'hindutva',\n",
              " 'narendramodi',\n",
              " 'jaishreeram',\n",
              " 'modi',\n",
              " 'hindustan',\n",
              " 'sanatandharma',\n",
              " 'vhp',\n",
              " 'bhagwa',\n",
              " 'asiaâ\\x80\\x99s',\n",
              " 'biggest',\n",
              " 'biocng',\n",
              " 'plant',\n",
              " 'madhya',\n",
              " 'pradeshâ\\x80\\x99s',\n",
              " 'indore',\n",
              " 'asia',\n",
              " 'bio',\n",
              " 'gas',\n",
              " 'nature',\n",
              " 'environment',\n",
              " 'precaution',\n",
              " 'development',\n",
              " 'madhyapradesh',\n",
              " 'indore',\n",
              " 'state',\n",
              " 'primeminister',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'indianewsnetdotcom',\n",
              " 'inn',\n",
              " 'indianewsnet',\n",
              " 'http',\n",
              " 'tcowxwawjjage',\n",
              " 'asia',\n",
              " 'bio',\n",
              " 'gas',\n",
              " 'nature',\n",
              " 'environment',\n",
              " 'precaution',\n",
              " 'development',\n",
              " 'madhyapradesh',\n",
              " 'indore',\n",
              " 'state',\n",
              " 'primeminister',\n",
              " 'modi',\n",
              " 'narendramodi',\n",
              " 'indianewsnetdotcom',\n",
              " 'inn',\n",
              " 'indianewsnet',\n",
              " 'during',\n",
              " 'emergency',\n",
              " 'used',\n",
              " 'wear',\n",
              " 'sikh',\n",
              " 'turban',\n",
              " 'hide',\n",
              " 'pm',\n",
              " 'modi',\n",
              " 'told',\n",
              " 'sikh',\n",
              " 'leader',\n",
              " 'http',\n",
              " 'tco6dhalwogdw',\n",
              " 'narendramodi',\n",
              " 'punjabelections2022',\n",
              " 'assemblyelections2022',\n",
              " 'narendramodi',\n",
              " 'punjabelections2022',\n",
              " 'assemblyelections2022',\n",
              " 'queen',\n",
              " 'elizabeth',\n",
              " 'tested',\n",
              " 'positive',\n",
              " 'covid19',\n",
              " 'pm',\n",
              " 'narendra',\n",
              " 'modi',\n",
              " 'uk',\n",
              " 'pm',\n",
              " 'boris',\n",
              " 'johnson',\n",
              " 'wish',\n",
              " 'speedy',\n",
              " 'recovery',\n",
              " 'queenelizabeth',\n",
              " 'thebuckinghampalace',\n",
              " 'elizabethii',\n",
              " 'pmnarendramodi',\n",
              " 'borisjohnson',\n",
              " 'covidisnotover',\n",
              " 'covid19',\n",
              " 'read',\n",
              " 'http',\n",
              " 'tcosfuojfijxt',\n",
              " 'http',\n",
              " 'tcowopdetsvh8',\n",
              " 'queenelizabeth',\n",
              " 'thebuckinghampalace',\n",
              " 'elizabethii',\n",
              " 'pmnarendramodi',\n",
              " 'borisjohnson',\n",
              " 'covidisnotover',\n",
              " 'covid19',\n",
              " 'modi',\n",
              " 'recall',\n",
              " 'ahmedabad',\n",
              " 'blast',\n",
              " 'say',\n",
              " 'party',\n",
              " 'sympathetic',\n",
              " 'terrorist',\n",
              " 'http',\n",
              " 'tco0tscoknw90',\n",
              " 'upelection2022',\n",
              " 'upassemblyelection2022',\n",
              " 'upassemblyelections2022',\n",
              " 'pmnarendramodi',\n",
              " 'bjp',\n",
              " 'upelection2022',\n",
              " 'upassemblyelection2022',\n",
              " 'upassemblyelections2022',\n",
              " 'pmnarendramodi',\n",
              " 'bjp']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_dataset = df_query['tweet'].tolist()\n",
        "tweet_query_keyword_extractor = keyword_extractor(keyword_dataset)"
      ],
      "metadata": {
        "id": "IhXLi1MqtCFt"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_query_keyword_extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HplmCxZVtH1U",
        "outputId": "907bb9b5-1878-48f2-bf71-1fde2ff90dc1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['modi',\n",
              " 'narendramodi',\n",
              " 'india',\n",
              " 'bjp',\n",
              " 'congress',\n",
              " 'ji',\n",
              " 'politics',\n",
              " 'pm',\n",
              " 'amitshah',\n",
              " 'minister',\n",
              " 'rahulgandhi',\n",
              " 'news',\n",
              " 'sikh',\n",
              " 'prime',\n",
              " 'people',\n",
              " 'indore',\n",
              " 'pmnarendramodi',\n",
              " 'statehood',\n",
              " 'declaring',\n",
              " 'hindu',\n",
              " 'read',\n",
              " 'priyankagandhi',\n",
              " 'indianpolitics',\n",
              " 'narendra',\n",
              " 'covid19',\n",
              " 'delhi',\n",
              " 'rss',\n",
              " 'mumbai',\n",
              " 'hinduism',\n",
              " 'yogiadityanath']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_keywords_yake = []\n",
        "kw_extractor = yake.KeywordExtractor(top=20, stopwords=None)\n",
        "keywords = kw_extractor.extract_keywords(' '.join(tweet_query))\n",
        "#keywords = kw_extractor.extract_keywords(' '.join(df_query['tweet'].tolist()))\n",
        "for kw, v in keywords:\n",
        "  print(\"Keyphrase: \",kw, \": score\", v)\n",
        "  for key in kw.split():\n",
        "    if(key.lower() not in tweet_keywords_yake):\n",
        "      tweet_keywords_yake.append(key.lower())\n",
        "\n",
        "print(tweet_keywords_yake)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZDm6Cznts-9",
        "outputId": "77bd5404-d0d9-4478-cea6-eb27620c4fab"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyphrase:  india bjp modi : score 3.124693022092362e-05\n",
            "Keyphrase:  narendramodi india bjp : score 6.037166731317872e-05\n",
            "Keyphrase:  bjp india narendramodi : score 6.037166731317872e-05\n",
            "Keyphrase:  india bjp narendramodi : score 6.037166731317872e-05\n",
            "Keyphrase:  bjp narendramodi india : score 6.037166731317872e-05\n",
            "Keyphrase:  modi india bjp : score 6.249386044184723e-05\n",
            "Keyphrase:  bjp narendramodi congress : score 6.461576268648576e-05\n",
            "Keyphrase:  congress bjp narendramodi : score 6.461576268648576e-05\n",
            "Keyphrase:  india narendramodi modi : score 6.581080854383824e-05\n",
            "Keyphrase:  narendramodi india modi : score 6.581080854383824e-05\n",
            "Keyphrase:  priyankagandhi rahulgandhi congress : score 6.790842832286181e-05\n",
            "Keyphrase:  bjp modi amitshah : score 6.851854888827196e-05\n",
            "Keyphrase:  rahulgandhi congress bjp : score 6.94561200328927e-05\n",
            "Keyphrase:  narendramodi modi congress : score 7.043825244061592e-05\n",
            "Keyphrase:  india modi amitshah : score 7.487064473666578e-05\n",
            "Keyphrase:  modi amitshah rahulgandhi : score 7.756272047694059e-05\n",
            "Keyphrase:  modi congress amitshah : score 8.013691280835908e-05\n",
            "Keyphrase:  prime minister modi : score 8.260812317526487e-05\n",
            "Keyphrase:  soniagandhi india bjp : score 8.933244596185653e-05\n",
            "Keyphrase:  modi amitshah politics : score 8.997304334446483e-05\n",
            "['india', 'bjp', 'modi', 'narendramodi', 'congress', 'priyankagandhi', 'rahulgandhi', 'amitshah', 'prime', 'minister', 'soniagandhi', 'politics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_preprocessed = []"
      ],
      "metadata": {
        "id": "0fZNQhToT43g"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing file name and data\n",
        "total_documents = 0\n",
        "path = '/content/drive/MyDrive/Tweelink_Dataset/Tweelink_Articles_Processed'\n",
        "for filename in glob(os.path.join(path, '*')):\n",
        "   with open(os.path.join(os.getcwd(), filename), 'r', encoding = 'utf-8',errors = 'ignore') as f:\n",
        "     filename = os.path.basename(f.name)\n",
        "     data = json.load(f)\n",
        "     d_date = data[\"Date\"]\n",
        "     if(d_date==\"\" or d_date==\"Date\"):\n",
        "       continue\n",
        "     format = '%Y-%m-%d'\n",
        " \n",
        "     d_present_date = datetime.datetime.strptime(d_date, format)\n",
        " \n",
        "     if(str(d_present_date.date()) not in [str(u_present_date.date()), str(u_prev_date.date()), str(u_next_date.date())]):\n",
        "       continue\n",
        "   \n",
        "     docs_preprocessed.append({'Name':filename, 'Data':data})\n",
        "     total_documents+=1\n",
        "print(total_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6fzO-H6T83w",
        "outputId": "07fc1679-2f92-49a5-bffb-1e67172d1d7b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_docs_list_for_base_hashtag(base_hashtag, base_date, docs_preprocessed):\n",
        "  relevant_docs_list = []\n",
        "  for doc in docs_preprocessed:\n",
        "    if doc['Data']['Base Hashtag']==base_hashtag:\n",
        "      current_date = datetime.datetime.strptime(base_date, format)\n",
        "      prev_date = current_date - datetime.timedelta(days=1)\n",
        "      next_date = current_date + datetime.timedelta(days=1)\n",
        "      if(doc['Data']['Date'] in [str(prev_date.date()), str(current_date.date()), str(next_date.date())]):\n",
        "        relevant_docs_list.append(doc['Name'])\n",
        "  return relevant_docs_list"
      ],
      "metadata": {
        "id": "ASFbpl047xKd"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(k, base_hashtag, base_date, prediction_list, docs_preprocessed):\n",
        "  relevant_docs_list = get_relevant_docs_list_for_base_hashtag(base_hashtag, base_date, docs_preprocessed)\n",
        "  num_of_relevant_results=0\n",
        "  for itr in range(k):\n",
        "    if (prediction_list[itr][0] in relevant_docs_list):\n",
        "      num_of_relevant_results+=1\n",
        "  return num_of_relevant_results/k"
      ],
      "metadata": {
        "id": "JdWZkYhc7yh7"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(max_k, base_hashtag, base_date, relevant_docs, docs_preprocessed):\n",
        "  average_precision=0\n",
        "  ctr=0\n",
        "  for k_val in range(1,max_k+1):\n",
        "    ctr+=1\n",
        "    precision_at_k_val = precision_at_k(k_val, base_hashtag, base_date, relevant_docs, docs_preprocessed)\n",
        "    #print('Hashtag: {}   Precision@{}: {}'.format(base_hashtag, k_val, precision_at_k_val))\n",
        "    average_precision += precision_at_k_val\n",
        "  return average_precision/ctr"
      ],
      "metadata": {
        "id": "k1XBPmJv73xD"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(k, base_hashtag, base_date, prediction_list, docs_preprocessed):\n",
        "  relevant_docs_list = get_relevant_docs_list_for_base_hashtag(base_hashtag, base_date, docs_preprocessed)\n",
        "  current_num_of_relevant_results=0\n",
        "  for itr in range(k):\n",
        "    if (prediction_list[itr][0] in relevant_docs_list):\n",
        "      current_num_of_relevant_results+=1\n",
        "  if(len(relevant_docs_list)==0):\n",
        "    return 0\n",
        "  return current_num_of_relevant_results/len(relevant_docs_list)"
      ],
      "metadata": {
        "id": "YJuX6kb277hg"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_recall(max_k, base_hashtag, base_date, relevant_docs, docs_preprocessed):\n",
        "  average_recall=0\n",
        "  ctr=0\n",
        "  for k_val in range(1,max_k+1):\n",
        "    ctr+=1\n",
        "    recall_at_k_val = recall_at_k(k_val, base_hashtag, base_date, relevant_docs, docs_preprocessed)\n",
        "    #print('Hashtag: {}   Recall@{}: {}'.format(base_hashtag, k_val, recall_at_k_val))\n",
        "    average_recall += recall_at_k_val\n",
        "  return average_recall/ctr"
      ],
      "metadata": {
        "id": "DiHZ2YSi783Y"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_relevant_documents_cosine_similarity_count_vectorizer(docs_preprocessed, processed_query):\n",
        "  cosine_similarities_cv = {}\n",
        "  for document in docs_preprocessed:\n",
        "    query_sent = ' '.join(map(str, processed_query))\n",
        "    doc_text_sent = ' '.join(map(str, document['Data']['Body_processed']))\n",
        "    data = [query_sent, doc_text_sent]\n",
        "    count_vectorizer = CountVectorizer(encoding='latin-1', decode_error='ignore', ngram_range=(1,2))\n",
        "    vector_matrix = count_vectorizer.fit_transform(data)\n",
        "    cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
        "    cosine_similarities_cv[document['Name']] = cosine_similarity_matrix[0][1]\n",
        "  relevant_docs = list( sorted(cosine_similarities_cv.items(), key=operator.itemgetter(1),reverse=True))[:20]\n",
        "  for i in range(len(relevant_docs)):\n",
        "    for j in range(len(docs_preprocessed)):\n",
        "      if(relevant_docs[i][0] == docs_preprocessed[j]['Name']):\n",
        "        relevant_docs[i] = (relevant_docs[i][0], relevant_docs[i][1], docs_preprocessed[j]['Data']['Date'] )\n",
        "\n",
        "  return relevant_docs"
      ],
      "metadata": {
        "id": "kq1KVcjncYkG"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_relevant_documents_cosine_similarity_tfidf_vectorizer(docs_preprocessed, processed_query):\n",
        "  cosine_similarities_tfidf = {}\n",
        "  for document in docs_preprocessed:\n",
        "    query_sent = ' '.join(map(str, processed_query))\n",
        "    doc_text_sent = ' '.join(map(str, document['Data']['Body_processed']))\n",
        "    data = [query_sent, doc_text_sent]\n",
        "    Tfidf_vect = TfidfVectorizer(encoding='latin-1', decode_error='ignore', ngram_range=(1,2))\n",
        "    vector_matrix = Tfidf_vect.fit_transform(data)\n",
        "    cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
        "    cosine_similarities_tfidf[document['Name']] = cosine_similarity_matrix[0][1]\n",
        "  relevant_docs = list( sorted(cosine_similarities_tfidf.items(), key=operator.itemgetter(1),reverse=True))[:20]\n",
        "  for i in range(len(relevant_docs)):\n",
        "    for j in range(len(docs_preprocessed)):\n",
        "      if(relevant_docs[i][0] == docs_preprocessed[j]['Name']):\n",
        "        relevant_docs[i] = (relevant_docs[i][0], relevant_docs[i][1], docs_preprocessed[j]['Data']['Date'] )\n",
        "\n",
        "  return relevant_docs"
      ],
      "metadata": {
        "id": "OZemps7wh0VO"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cosine Similarity Count Vectorizer**"
      ],
      "metadata": {
        "id": "87TlFE1juGUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plain Model (Cosine Similarity Count Vectorizer)"
      ],
      "metadata": {
        "id": "Ty_NvU4DuLSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plain Model without YAKE / Keyword Extraction (Cosine Similarity Count Vectorizer)\n",
        "relevant_docs_cs_cv_plain = find_relevant_documents_cosine_similarity_count_vectorizer(docs_preprocessed, tweet_query)\n",
        "\n",
        "for rank, doc in enumerate(relevant_docs_cs_cv_plain):\n",
        "  print('Rank: {} Relevant Document: {}'.format(rank+1,doc))\n",
        "\n",
        "print()\n",
        "\n",
        "mean_average_precision_hashtag_cs_cv_plain = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_cv_plain, docs_preprocessed)\n",
        "print('Mean Average Precision Plain Model (Cosine Similarity Count Vectorizer) : {}'.format(mean_average_precision_hashtag_cs_cv_plain))\n",
        "\n",
        "mean_average_recall_hashtag_cs_cv_plain = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_cv_plain, docs_preprocessed)\n",
        "print('Mean Average Recall Plain Model (Cosine Similarity Count Vectorizer) : {}'.format(mean_average_recall_hashtag_cs_cv_plain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsU5NnWRuYFH",
        "outputId": "6bd32207-01f5-4d0c-c1d7-8a73f6c3147c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1 Relevant Document: ('narendramodi_305.json', 0.28168876214240035, '2022-02-20')\n",
            "Rank: 2 Relevant Document: ('narendramodi_302.json', 0.23484102625002676, '2022-02-20')\n",
            "Rank: 3 Relevant Document: ('narendramodi_255.json', 0.22117173887810665, '2022-02-19')\n",
            "Rank: 4 Relevant Document: ('narendramodi_253.json', 0.21508677052407602, '2022-02-19')\n",
            "Rank: 5 Relevant Document: ('narendramodi_306.json', 0.2024842279618608, '2022-02-20')\n",
            "Rank: 6 Relevant Document: ('narendramodi_254.json', 0.18006181776427088, '2022-02-19')\n",
            "Rank: 7 Relevant Document: ('narendramodi_307.json', 0.16357491810657177, '2022-02-20')\n",
            "Rank: 8 Relevant Document: ('PunjabElections2022_127.json', 0.1527494108997967, '2022-02-20')\n",
            "Rank: 9 Relevant Document: ('narendramodi_210.json', 0.14965611128060435, '2022-02-19')\n",
            "Rank: 10 Relevant Document: ('narendramodi_256.json', 0.14748493921984668, '2022-02-19')\n",
            "Rank: 11 Relevant Document: ('narendramodi_303.json', 0.14425546563199237, '2022-02-20')\n",
            "Rank: 12 Relevant Document: ('narendramodi_301.json', 0.14119849711464655, '2022-02-20')\n",
            "Rank: 13 Relevant Document: ('narendramodi_251.json', 0.12868597101025261, '2022-02-19')\n",
            "Rank: 14 Relevant Document: ('narendramodi_304.json', 0.12842116646756635, '2022-02-20')\n",
            "Rank: 15 Relevant Document: ('hijab_286.json', 0.12296672441909542, '2022-02-19')\n",
            "Rank: 16 Relevant Document: ('narendramodi_258.json', 0.11706772482798004, '2022-02-19')\n",
            "Rank: 17 Relevant Document: ('PunjabElections2022_121.json', 0.11611340509410664, '2022-02-20')\n",
            "Rank: 18 Relevant Document: ('PunjabElections2022_123.json', 0.11207965813953243, '2022-02-20')\n",
            "Rank: 19 Relevant Document: ('narendramodi_260.json', 0.1117550812845643, '2022-02-19')\n",
            "Rank: 20 Relevant Document: ('narendramodi_257.json', 0.10168488550775588, '2022-02-19')\n",
            "\n",
            "Mean Average Precision Plain Model (Cosine Similarity Count Vectorizer) : 0.9136871178357249\n",
            "Mean Average Recall Plain Model (Cosine Similarity Count Vectorizer) : 0.43809523809523815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Keyword Extractor (Cosine Similarity Count Vectorizer)"
      ],
      "metadata": {
        "id": "v4sF3KZuvSuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with Keyword Extractor (Cosine Similarity Count Vectorizer)\n",
        "relevant_docs_cs_cv_keyword_extractor = find_relevant_documents_cosine_similarity_count_vectorizer(docs_preprocessed, tweet_query_keyword_extractor[:20])\n",
        "\n",
        "for rank, doc in enumerate(relevant_docs_cs_cv_keyword_extractor):\n",
        "  print('Rank: {} Relevant Document: {}'.format(rank+1,doc))\n",
        "\n",
        "print()\n",
        "\n",
        "mean_average_precision_hashtag_cs_cv_keyword_extractor = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_cv_keyword_extractor, docs_preprocessed)\n",
        "print('Mean Average Precision Keyword Extractor Model (Cosine Similarity Count Vectorizer) : {}'.format(mean_average_precision_hashtag_cs_cv_keyword_extractor))\n",
        "\n",
        "mean_average_recall_hashtag_cs_cv_keyword_extractor = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_cv_keyword_extractor, docs_preprocessed)\n",
        "print('Mean Average Recall Keyword Extractor Model (Cosine Similarity Count Vectorizer) : {}'.format(mean_average_recall_hashtag_cs_cv_keyword_extractor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-CSUMHKvcI8",
        "outputId": "d9a7afec-3a1d-44bf-dba2-e277b5e7aa1f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1 Relevant Document: ('narendramodi_305.json', 0.21253453081078813, '2022-02-20')\n",
            "Rank: 2 Relevant Document: ('narendramodi_253.json', 0.20593743545627882, '2022-02-19')\n",
            "Rank: 3 Relevant Document: ('narendramodi_255.json', 0.18595724992664922, '2022-02-19')\n",
            "Rank: 4 Relevant Document: ('narendramodi_302.json', 0.1695848845000006, '2022-02-20')\n",
            "Rank: 5 Relevant Document: ('narendramodi_257.json', 0.14423618685756168, '2022-02-19')\n",
            "Rank: 6 Relevant Document: ('narendramodi_306.json', 0.13456195054520434, '2022-02-20')\n",
            "Rank: 7 Relevant Document: ('narendramodi_256.json', 0.13135001086855977, '2022-02-19')\n",
            "Rank: 8 Relevant Document: ('narendramodi_210.json', 0.12921486684109101, '2022-02-19')\n",
            "Rank: 9 Relevant Document: ('narendramodi_303.json', 0.12277257249525216, '2022-02-20')\n",
            "Rank: 10 Relevant Document: ('narendramodi_304.json', 0.12124131481160959, '2022-02-20')\n",
            "Rank: 11 Relevant Document: ('PunjabElections2022_127.json', 0.11812189042910176, '2022-02-20')\n",
            "Rank: 12 Relevant Document: ('narendramodi_307.json', 0.11745897464899584, '2022-02-20')\n",
            "Rank: 13 Relevant Document: ('narendramodi_260.json', 0.11262044974183757, '2022-02-19')\n",
            "Rank: 14 Relevant Document: ('narendramodi_254.json', 0.11145203711152377, '2022-02-19')\n",
            "Rank: 15 Relevant Document: ('PunjabElections2022_121.json', 0.09396819714698793, '2022-02-20')\n",
            "Rank: 16 Relevant Document: ('narendramodi_251.json', 0.09268678093487835, '2022-02-19')\n",
            "Rank: 17 Relevant Document: ('PunjabElections2022_123.json', 0.09132938483219746, '2022-02-20')\n",
            "Rank: 18 Relevant Document: ('UNWFPtosavesoil_153.json', 0.08393881535871821, '2022-02-21')\n",
            "Rank: 19 Relevant Document: ('hijab_286.json', 0.08372336408665788, '2022-02-19')\n",
            "Rank: 20 Relevant Document: ('shivamogga_291.json', 0.08311716349233828, '2022-02-21')\n",
            "\n",
            "Mean Average Precision Keyword Extractor Model (Cosine Similarity Count Vectorizer) : 0.9228610944439117\n",
            "Mean Average Recall Keyword Extractor Model (Cosine Similarity Count Vectorizer) : 0.43809523809523815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with YAKE (Cosine Similarity Count Vectorizer)"
      ],
      "metadata": {
        "id": "IK7PnL_lwBwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with YAKE (Cosine Similarity Count Vectorizer)\n",
        "relevant_docs_cs_cv_yake = find_relevant_documents_cosine_similarity_count_vectorizer(docs_preprocessed, tweet_keywords_yake)\n",
        "\n",
        "for rank, doc in enumerate(relevant_docs_cs_cv_yake):\n",
        "  print('Rank: {} Relevant Document: {}'.format(rank+1,doc))\n",
        "\n",
        "print()\n",
        "\n",
        "mean_average_precision_hashtag_cs_cv_yake = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_cv_yake, docs_preprocessed)\n",
        "print('Mean Average Precision YAKE Model (Cosine Similarity Count Vectorizer) : {}'.format(mean_average_precision_hashtag_cs_cv_yake))\n",
        "\n",
        "mean_average_recall_hashtag_cs_cv_yake = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_cv_yake, docs_preprocessed)\n",
        "print('Mean Average Recall YAKE Model (Cosine Similarity Count Vectorizer) : {}'.format(mean_average_recall_hashtag_cs_cv_yake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR41bEZawSfM",
        "outputId": "15e66b5a-a166-4321-bc0c-edc414c3e404"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1 Relevant Document: ('narendramodi_253.json', 0.273132019184533, '2022-02-19')\n",
            "Rank: 2 Relevant Document: ('narendramodi_305.json', 0.16605392158402155, '2022-02-20')\n",
            "Rank: 3 Relevant Document: ('narendramodi_302.json', 0.16562152868272317, '2022-02-20')\n",
            "Rank: 4 Relevant Document: ('narendramodi_306.json', 0.16491559295004962, '2022-02-20')\n",
            "Rank: 5 Relevant Document: ('narendramodi_210.json', 0.14422285225885337, '2022-02-19')\n",
            "Rank: 6 Relevant Document: ('PunjabElections2022_127.json', 0.13535722633825173, '2022-02-20')\n",
            "Rank: 7 Relevant Document: ('narendramodi_251.json', 0.12931515002796792, '2022-02-19')\n",
            "Rank: 8 Relevant Document: ('narendramodi_254.json', 0.12698851640921516, '2022-02-19')\n",
            "Rank: 9 Relevant Document: ('PunjabElections2022_121.json', 0.11765650429228865, '2022-02-20')\n",
            "Rank: 10 Relevant Document: ('narendramodi_255.json', 0.1153087344543216, '2022-02-19')\n",
            "Rank: 11 Relevant Document: ('PunjabElections2022_123.json', 0.11011720064322529, '2022-02-20')\n",
            "Rank: 12 Relevant Document: ('narendramodi_303.json', 0.1065806789033412, '2022-02-20')\n",
            "Rank: 13 Relevant Document: ('narendramodi_307.json', 0.10548399965336058, '2022-02-20')\n",
            "Rank: 14 Relevant Document: ('hijab_286.json', 0.1044796358373182, '2022-02-19')\n",
            "Rank: 15 Relevant Document: ('narendramodi_256.json', 0.09825720469315735, '2022-02-19')\n",
            "Rank: 16 Relevant Document: ('QueenElizabeth_153.json', 0.09615516865505219, '2022-02-20')\n",
            "Rank: 17 Relevant Document: ('narendramodi_260.json', 0.09489195770724576, '2022-02-19')\n",
            "Rank: 18 Relevant Document: ('ScottyFromWelding_163.json', 0.09383881776971763, '2022-02-20')\n",
            "Rank: 19 Relevant Document: ('JohnsonOut21_45.json', 0.09302108199972713, '2022-02-20')\n",
            "Rank: 20 Relevant Document: ('narendramodi_304.json', 0.0925486198105478, '2022-02-20')\n",
            "\n",
            "Mean Average Precision YAKE Model (Cosine Similarity Count Vectorizer) : 0.8089502239676387\n",
            "Mean Average Recall YAKE Model (Cosine Similarity Count Vectorizer) : 0.37142857142857133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cosine Similarity TF-IDF Vectorizer**"
      ],
      "metadata": {
        "id": "rPwKCN2vyROm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plain Model (Cosine Similarity TF-IDF Vectorizer)"
      ],
      "metadata": {
        "id": "WUyB5l37yXdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plain Model without YAKE / Keyword Extraction (Cosine Similarity TF-IDF Vectorizer)\n",
        "relevant_docs_cs_tfidf_plain = find_relevant_documents_cosine_similarity_tfidf_vectorizer(docs_preprocessed, tweet_query)\n",
        "\n",
        "for rank, doc in enumerate(relevant_docs_cs_tfidf_plain):\n",
        "  print('Rank: {} Relevant Document: {}'.format(rank+1,doc))\n",
        "\n",
        "print()\n",
        "\n",
        "mean_average_precision_hashtag_cs_tfidf_plain = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf_plain, docs_preprocessed)\n",
        "print('Mean Average Precision Plain Model (Cosine Similarity TF-IDF Vectorizer) : {}'.format(mean_average_precision_hashtag_cs_tfidf_plain))\n",
        "\n",
        "mean_average_recall_hashtag_cs_tfidf_plain = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf_plain, docs_preprocessed)\n",
        "print('Mean Average Recall Plain Model (Cosine Similarity TF-IDF Vectorizer) : {}'.format(mean_average_recall_hashtag_cs_tfidf_plain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyJ0i-rly8vc",
        "outputId": "efa7f37f-7114-4db7-8746-bc1afd3b1e09"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1 Relevant Document: ('narendramodi_305.json', 0.18222995233267084, '2022-02-20')\n",
            "Rank: 2 Relevant Document: ('narendramodi_302.json', 0.1439862208783998, '2022-02-20')\n",
            "Rank: 3 Relevant Document: ('narendramodi_253.json', 0.1336398277170659, '2022-02-19')\n",
            "Rank: 4 Relevant Document: ('narendramodi_255.json', 0.1318691603346738, '2022-02-19')\n",
            "Rank: 5 Relevant Document: ('narendramodi_306.json', 0.12881524820812473, '2022-02-20')\n",
            "Rank: 6 Relevant Document: ('narendramodi_254.json', 0.10940966900970286, '2022-02-19')\n",
            "Rank: 7 Relevant Document: ('narendramodi_307.json', 0.10378234442887901, '2022-02-20')\n",
            "Rank: 8 Relevant Document: ('PunjabElections2022_127.json', 0.09168201390292398, '2022-02-20')\n",
            "Rank: 9 Relevant Document: ('narendramodi_303.json', 0.08715043016612838, '2022-02-20')\n",
            "Rank: 10 Relevant Document: ('narendramodi_210.json', 0.08688658855037971, '2022-02-19')\n",
            "Rank: 11 Relevant Document: ('narendramodi_256.json', 0.0837684056510868, '2022-02-19')\n",
            "Rank: 12 Relevant Document: ('narendramodi_301.json', 0.0829266867770417, '2022-02-20')\n",
            "Rank: 13 Relevant Document: ('narendramodi_304.json', 0.0749375414774482, '2022-02-20')\n",
            "Rank: 14 Relevant Document: ('narendramodi_251.json', 0.07251119857845498, '2022-02-19')\n",
            "Rank: 15 Relevant Document: ('PunjabElections2022_121.json', 0.06754398472087857, '2022-02-20')\n",
            "Rank: 16 Relevant Document: ('hijab_286.json', 0.06746182943155747, '2022-02-19')\n",
            "Rank: 17 Relevant Document: ('PunjabElections2022_123.json', 0.06501612514543678, '2022-02-20')\n",
            "Rank: 18 Relevant Document: ('narendramodi_258.json', 0.06491816435658769, '2022-02-19')\n",
            "Rank: 19 Relevant Document: ('narendramodi_260.json', 0.06334154641264556, '2022-02-19')\n",
            "Rank: 20 Relevant Document: ('narendramodi_257.json', 0.0619882545416135, '2022-02-19')\n",
            "\n",
            "Mean Average Precision Plain Model (Cosine Similarity TF-IDF Vectorizer) : 0.9076209413651366\n",
            "Mean Average Recall Plain Model (Cosine Similarity TF-IDF Vectorizer) : 0.43333333333333324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Keyword Extractor (Cosine Similarity TF-IDF Vectorizer)"
      ],
      "metadata": {
        "id": "PxJq6a6wzc4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with Keyword Extractor (Cosine Similarity TF-IDF Vectorizer)\n",
        "relevant_docs_cs_tfidf_keyword_extractor = find_relevant_documents_cosine_similarity_tfidf_vectorizer(docs_preprocessed, tweet_query_keyword_extractor[:20])\n",
        "\n",
        "for rank, doc in enumerate(relevant_docs_cs_tfidf_keyword_extractor):\n",
        "  print('Rank: {} Relevant Document: {}'.format(rank+1,doc))\n",
        "\n",
        "print()\n",
        "\n",
        "mean_average_precision_hashtag_cs_tfidf_keyword_extractor = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf_keyword_extractor, docs_preprocessed)\n",
        "print('Mean Average Precision Keyword Extractor Model (Cosine Similarity TF-IDF Vectorizer) : {}'.format(mean_average_precision_hashtag_cs_tfidf_keyword_extractor))\n",
        "\n",
        "mean_average_recall_hashtag_cs_tfidf_keyword_extractor = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf_keyword_extractor, docs_preprocessed)\n",
        "print('Mean Average Recall Keyword Extractor Model (Cosine Similarity TF-IDF Vectorizer) : {}'.format(mean_average_recall_hashtag_cs_tfidf_keyword_extractor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRVxJxQqzkU0",
        "outputId": "67c74c38-57fe-4ca5-d59d-0effe7dca873"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1 Relevant Document: ('narendramodi_305.json', 0.12635397883270644, '2022-02-20')\n",
            "Rank: 2 Relevant Document: ('narendramodi_253.json', 0.11889875064170931, '2022-02-19')\n",
            "Rank: 3 Relevant Document: ('narendramodi_255.json', 0.10598925279440591, '2022-02-19')\n",
            "Rank: 4 Relevant Document: ('narendramodi_302.json', 0.09517619897769045, '2022-02-20')\n",
            "Rank: 5 Relevant Document: ('narendramodi_257.json', 0.08148814872584768, '2022-02-19')\n",
            "Rank: 6 Relevant Document: ('narendramodi_306.json', 0.07416011222667795, '2022-02-20')\n",
            "Rank: 7 Relevant Document: ('narendramodi_256.json', 0.0720358314685524, '2022-02-19')\n",
            "Rank: 8 Relevant Document: ('narendramodi_210.json', 0.0710105303033034, '2022-02-19')\n",
            "Rank: 9 Relevant Document: ('narendramodi_303.json', 0.06793958694616374, '2022-02-20')\n",
            "Rank: 10 Relevant Document: ('narendramodi_304.json', 0.067214367017986, '2022-02-20')\n",
            "Rank: 11 Relevant Document: ('PunjabElections2022_127.json', 0.06517111892190373, '2022-02-20')\n",
            "Rank: 12 Relevant Document: ('narendramodi_307.json', 0.06363816792706793, '2022-02-20')\n",
            "Rank: 13 Relevant Document: ('narendramodi_260.json', 0.061672867648327856, '2022-02-19')\n",
            "Rank: 14 Relevant Document: ('narendramodi_254.json', 0.06039446187695273, '2022-02-19')\n",
            "Rank: 15 Relevant Document: ('PunjabElections2022_121.json', 0.05094428841972861, '2022-02-20')\n",
            "Rank: 16 Relevant Document: ('narendramodi_251.json', 0.049625802133622846, '2022-02-19')\n",
            "Rank: 17 Relevant Document: ('PunjabElections2022_123.json', 0.04939234788829486, '2022-02-20')\n",
            "Rank: 18 Relevant Document: ('hijab_286.json', 0.04485104054332821, '2022-02-19')\n",
            "Rank: 19 Relevant Document: ('shivamogga_291.json', 0.04484137415173492, '2022-02-21')\n",
            "Rank: 20 Relevant Document: ('UNWFPtosavesoil_153.json', 0.044761966260446956, '2022-02-21')\n",
            "\n",
            "Mean Average Precision Keyword Extractor Model (Cosine Similarity TF-IDF Vectorizer) : 0.9228610944439117\n",
            "Mean Average Recall Keyword Extractor Model (Cosine Similarity TF-IDF Vectorizer) : 0.43809523809523815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with YAKE (Cosine Similarity TF-IDF Vectorizer)"
      ],
      "metadata": {
        "id": "VsQt5XsCzxcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with YAKE (Cosine Similarity TF-IDF Vectorizer)\n",
        "relevant_docs_cs_tfidf_yake = find_relevant_documents_cosine_similarity_tfidf_vectorizer(docs_preprocessed, tweet_keywords_yake)\n",
        "\n",
        "for rank, doc in enumerate(relevant_docs_cs_tfidf_yake):\n",
        "  print('Rank: {} Relevant Document: {}'.format(rank+1,doc))\n",
        "\n",
        "print()\n",
        "\n",
        "mean_average_precision_hashtag_cs_tfidf_yake = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf_yake, docs_preprocessed)\n",
        "print('Mean Average Precision YAKE Model (Cosine Similarity TF-IDF Vectorizer) : {}'.format(mean_average_precision_hashtag_cs_tfidf_yake))\n",
        "\n",
        "mean_average_recall_hashtag_cs_tfidf_yake = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf_yake, docs_preprocessed)\n",
        "print('Mean Average Recall YAKE Model (Cosine Similarity TF-IDF Vectorizer) : {}'.format(mean_average_recall_hashtag_cs_tfidf_yake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbJ9t2RAzw3f",
        "outputId": "0f462b46-3c7c-482f-9d6e-60ae6ddbb627"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 1 Relevant Document: ('narendramodi_253.json', 0.16282569020089283, '2022-02-19')\n",
            "Rank: 2 Relevant Document: ('narendramodi_305.json', 0.09616930342608403, '2022-02-20')\n",
            "Rank: 3 Relevant Document: ('narendramodi_302.json', 0.09321627144768442, '2022-02-20')\n",
            "Rank: 4 Relevant Document: ('narendramodi_306.json', 0.09228946896030002, '2022-02-20')\n",
            "Rank: 5 Relevant Document: ('narendramodi_210.json', 0.0803609607143747, '2022-02-19')\n",
            "Rank: 6 Relevant Document: ('PunjabElections2022_127.json', 0.0770983126167595, '2022-02-20')\n",
            "Rank: 7 Relevant Document: ('narendramodi_251.json', 0.07101863658235845, '2022-02-19')\n",
            "Rank: 8 Relevant Document: ('narendramodi_254.json', 0.07094382081653591, '2022-02-19')\n",
            "Rank: 9 Relevant Document: ('PunjabElections2022_121.json', 0.06523265709115568, '2022-02-20')\n",
            "Rank: 10 Relevant Document: ('narendramodi_255.json', 0.06373921511441341, '2022-02-19')\n",
            "Rank: 11 Relevant Document: ('PunjabElections2022_123.json', 0.060883126488200996, '2022-02-20')\n",
            "Rank: 12 Relevant Document: ('narendramodi_303.json', 0.05926352321919098, '2022-02-20')\n",
            "Rank: 13 Relevant Document: ('narendramodi_307.json', 0.057322491770507356, '2022-02-20')\n",
            "Rank: 14 Relevant Document: ('hijab_286.json', 0.05610787453381678, '2022-02-19')\n",
            "Rank: 15 Relevant Document: ('narendramodi_256.json', 0.053371180133333376, '2022-02-19')\n",
            "Rank: 16 Relevant Document: ('QueenElizabeth_153.json', 0.05161192506037837, '2022-02-20')\n",
            "Rank: 17 Relevant Document: ('narendramodi_260.json', 0.051379407370472585, '2022-02-19')\n",
            "Rank: 18 Relevant Document: ('narendramodi_304.json', 0.05128599585425829, '2022-02-20')\n",
            "Rank: 19 Relevant Document: ('ScottyFromWelding_163.json', 0.049952783283464905, '2022-02-20')\n",
            "Rank: 20 Relevant Document: ('JohnsonOut21_45.json', 0.04950267348663039, '2022-02-20')\n",
            "\n",
            "Mean Average Precision YAKE Model (Cosine Similarity TF-IDF Vectorizer) : 0.8143595806927848\n",
            "Mean Average Recall YAKE Model (Cosine Similarity TF-IDF Vectorizer) : 0.3761904761904761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Across all hashtags**"
      ],
      "metadata": {
        "id": "zxyJ3ooRzXwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# global_list = [['narendramodi', '2022-02-14', 'india'],['UkraineRussiaCrisis', '2022-02-14', 'ukraine'],['IPL', '2022-02-14', 'india'],['TaylorSwift', '2022-02-14', 'USA'],['IndiaFightsCorona', '2022-02-14', 'india'],['narendramodi', '2022-02-15', 'india'],['UkraineRussiaCrisis', '2022-02-15', 'ukraine'],['IPL', '2022-02-15', 'india'],['TaylorSwift', '2022-02-15', 'USA'],['IndiaFightsCorona', '2022-02-15', 'india'],['narendramodi', '2022-02-16', 'india'],['UkraineRussiaCrisis', '2022-02-16', 'ukraine'],['IPL', '2022-02-16', 'india'],['TaylorSwift', '2022-02-16', 'USA'],['IndiaFightsCorona', '2022-02-16', 'india'],['narendramodi', '2022-02-17', 'india'],['UkraineRussiaCrisis', '2022-02-17', 'ukraine'],['IPL', '2022-02-17', 'india'],['TaylorSwift', '2022-02-17', 'USA'],['IndiaFightsCorona', '2022-02-17', 'india'],['narendramodi', '2022-02-18', 'india'],['UkraineRussiaCrisis', '2022-02-18', 'ukraine'],['IPL', '2022-02-18', 'india'],['TaylorSwift', '2022-02-18', 'USA'],['IndiaFightsCorona', '2022-02-18', 'india'],['narendramodi', '2022-02-19', 'india'],['UkraineRussiaCrisis', '2022-02-19', 'ukraine'],['IPL', '2022-02-19', 'india'],['hijab', '2022-02-19', 'india'],['vaccine', '2022-02-19', 'india'],['MillionAtIndiaPavilion', '2022-02-14', 'UAE'],['PunjabPanjeNaal', '2022-02-14', 'India'],['Euphoria', '2022-02-14', 'World'],['OscarsFanFavorite', '2022-02-14', 'World'],['ShameOnBirenSingh', '2022-02-14', 'india'],['BappiLahiri', '2022-02-16', 'india'],['BlandDoritos', '2022-02-16', 'USA'],['VERZUZ', '2022-02-16', 'USA'],['DragRaceUK', '2022-02-16', 'United Kingdom'],['BoycottWalgreens', '2022-02-18', 'USA'],['PunjabElections2022', '2022-02-20', 'india'],['WriddhimanSaha', '2022-02-20', 'india'],['stormfranklin', '2022-02-20', 'USA'],['QueenElizabeth', '2022-02-20', 'United Kingdom'],['ScottyFromWelding', '2022-02-20', 'Australia'],['CarabaoCupFinal', '2022-02-27', 'London'],['NZvSA', '2022-02-28', 'New Zealand'],['IPCC', '2022-02-28', 'Worldwide'],['SuperBowl', '2022-02-14', 'USA'],['MultiverseOfMadness', '2022-02-14', 'USA'],['Eminem', '2022-02-14', 'USA'],['IPLAuction', '2022-02-14', 'india'],['JohnsonOut21', '2022-02-14', 'United Kingdom'],['Cyberpunk2077', '2022-02-15', 'Worldwide'],['Wordle242', '2022-02-15', 'Worldwide'],['DeepSidhu', '2022-02-15', 'india'],['CanadaHasFallen', '2022-02-15', 'canada'],['IStandWithTrudeau', '2022-02-15', 'canada'],['CNNPHVPDebate', '2022-02-26', 'philippines'],['qldfloods', '2022-02-26', 'australia'],['Eurovision', '2022-02-26', 'worldwide'],['IndiansInUkraine', '2022-02-26', 'india'],['PritiPatel', '2022-02-26', 'united kingdom'],['TaylorCatterall', '2022-02-27', 'united kingdom'],['PSLFinal', '2022-02-27', 'pakistan'],['AustraliaDecides', '2022-02-27', 'australia'],['WorldNGODay', '2022-02-27', 'worldwide'],['TheBatman', '2022-02-28', 'USA'],['NationalScienceDay', '2022-02-28', 'india'],['msdtrong', '2022-02-14', 'india'],['Boycott_ChennaiSuperKings', '2022-02-14', 'india'],['GlanceJio', '2022-02-14', 'india'],['ArabicKuthu', '2022-02-14', 'india'],['Djokovic', '2022-02-15', 'australia'],['Real Madrid', '2022-02-15', 'santiago'],['bighit', '2022-02-15', 'korea'],['Maxwell', '2022-02-15', 'australia'],['mafsau', '2022-02-16', 'australia'],['channi', '2022-02-16', 'punjab'],['ayalaan', '2022-02-16', 'india'],['jkbose', '2022-02-16', 'india'],['HappyBirthdayPrinceSK', '2022-02-16', 'india'],['RandomActsOfKindnessDay', '2022-02-17', 'worldwide'],['happybirthdayjhope', '2022-02-17', 'korea'],['mohsinbaig', '2022-02-17', 'pakistan'],['aewdynamite', '2022-02-17', 'worldwide'],['aaraattu', '2022-02-17', 'india'],['ShivajiJayanti', '2022-02-18', 'india'],['PlotToKillModi', '2022-02-18', 'india'],['NationalDrinkWineDay', '2022-02-18', 'usa'],['HorizonForbiddenWest', '2022-02-18', 'worldwide'],['BoycottWalgreens', '2022-02-18', 'usa'],['CallTheMidwife', '2022-02-20', 'worldwide'],['OperationDudula', '2022-02-20', 'south africa'],['truthsocial', '2022-02-21', 'usa'],['nbaallstar', '2022-02-21', 'usa'],['shivamogga', '2022-02-21', 'india'],['HalftimeShow', '2022-02-14', 'usa'],['OttawaStrong', '2022-02-14', 'canada'],['DrDre', '2022-02-14', 'usa'],['BattleOfBillingsBridge', '2022-02-14', 'usa'],['FullyFaltooNFTdrop', '2022-02-14', 'worldwide'],['AK61', '2022-02-15', 'india'],['sandhyamukherjee', '2022-02-15', 'india'],['MUNBHA', '2022-02-15', 'worldwide'],['nursesstrike', '2022-02-15', 'australia'],['Realme9ProPlus', '2022-02-16', 'worldwide'],['KarnatakaHijabControversy', '2022-02-16', 'india'],['BJPwinningUP', '2022-02-16', 'india'],['Punjab_With_Modi', '2022-02-16', 'india'],['PushpaTheRule', '2022-02-16', 'india'],['RehmanMalik', '2022-02-22', 'india'],['harisrauf', '2022-02-22', 'pakistan'],['Rosettenville', '2022-02-22', 'south africa'],['NFU22', '2022-02-22', 'worldwide'],['justiceforharsha', '2022-02-22', 'india'],['wordle251', '2022-02-24', 'worldwide'],['ARSWOL', '2022-02-24', 'worldwide'],['stopwar', '2022-02-24', 'worldwide'],['PrayForPeace', '2022-02-24', 'worldwide'],['StopPutinNOW', '2022-02-24', 'worldwide'],['TeamGirlsCup', '2022-02-25', 'worldwide'],['Canucks', '2022-02-25', 'worldwide'],['PinkShirtDay', '2022-02-25', 'canada'],['superrugbypacific', '2022-02-25', 'australia']]"
      ],
      "metadata": {
        "id": "Ft7ith1b86zx"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# global_average_mean_average_precision_cs_cv = []\n",
        "# global_mean_average_recall_cs_cv = []\n",
        "\n",
        "# global_average_mean_average_precision_cs_tfidf = []\n",
        "# global_mean_average_recall_cs_tfidf = []\n",
        "\n",
        "# for iter in tqdm(range(len(global_list))):\n",
        "#   u_base_hashtag = global_list[iter][0]\n",
        "#   u_time = global_list[iter][1]\n",
        "#   u_location = global_list[iter][2]\n",
        "#   tweet_query = []\n",
        "#   format = '%Y-%m-%d'\n",
        "#   u_present_date = datetime.datetime.strptime(u_time, format)\n",
        "#   u_prev_date = u_present_date - datetime.timedelta(days=1)\n",
        "#   u_next_date = u_present_date + datetime.timedelta(days=1)\n",
        "#   df_query = df.loc[df['hashtags'].str.contains(u_base_hashtag) & df['Date_Only'].isin([str(u_present_date.date()), str(u_prev_date.date()), str(u_next_date.date())])]\n",
        "\n",
        "#   for tweet in df_query['Preprocessed_Data']:\n",
        "#     tweet_query.extend(tweet)\n",
        "  \n",
        "#   # tweet_keywords = []\n",
        "#   # kw_extractor = yake.KeywordExtractor(top=20, stopwords=None)\n",
        "#   # keywords = kw_extractor.extract_keywords(' '.join(tweet_query))\n",
        "#   # for kw, v in keywords:\n",
        "#   #   #print(\"Keyphrase: \",kw, \": score\", v)\n",
        "#   #   for key in kw.split():\n",
        "#   #     if(key not in tweet_keywords):\n",
        "#   #       tweet_keywords.append(key)\n",
        "  \n",
        "#   docs_preprocessed = []\n",
        "\n",
        "#   total_documents = 0\n",
        "#   path = '/content/drive/MyDrive/Tweelink_Dataset/Tweelink_Articles_Processed'\n",
        "#   for filename in glob(os.path.join(path, '*')):\n",
        "#     with open(os.path.join(os.getcwd(), filename), 'r', encoding = 'utf-8',errors = 'ignore') as f:\n",
        "#       filename = os.path.basename(f.name)\n",
        "#       data = json.load(f)\n",
        "#       d_date = data[\"Date\"]\n",
        "#       if(d_date==\"\" or d_date==\"Date\"):\n",
        "#         continue\n",
        "#       format = '%Y-%m-%d'\n",
        "  \n",
        "#       d_present_date = datetime.datetime.strptime(d_date, format)\n",
        "  \n",
        "#       if(str(d_present_date.date()) not in [str(u_present_date.date()), str(u_prev_date.date()), str(u_next_date.date())]):\n",
        "#         continue\n",
        "    \n",
        "#       docs_preprocessed.append({'Name':filename, 'Data':data})\n",
        "#       total_documents+=1\n",
        "  \n",
        "#   relevant_docs_cs_cv = find_relevant_documents_cosine_similarity_count_vectorizer(docs_preprocessed, tweet_query)\n",
        "#   mean_average_precision_hashtag_cs_cv = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_cv, docs_preprocessed)\n",
        "#   global_average_mean_average_precision_cs_cv.append(mean_average_precision_hashtag_cs_cv)\n",
        "#   mean_average_recall_hashtag_cs_cv = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_cv, docs_preprocessed)\n",
        "#   global_mean_average_recall_cs_cv.append(mean_average_recall_hashtag_cs_cv)\n",
        "\n",
        "#   relevant_docs_cs_tfidf = find_relevant_documents_cosine_similarity_tfidf_vectorizer(docs_preprocessed, tweet_query)\n",
        "#   mean_average_precision_hashtag_cs_tfidf = mean_average_precision(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf, docs_preprocessed)\n",
        "#   global_average_mean_average_precision_cs_tfidf.append(mean_average_precision_hashtag_cs_tfidf)\n",
        "#   mean_average_recall_hashtag_cs_tfidf = mean_average_recall(20, u_base_hashtag, u_time, relevant_docs_cs_tfidf, docs_preprocessed)\n",
        "#   global_mean_average_recall_cs_tfidf.append(mean_average_recall_hashtag_cs_tfidf)"
      ],
      "metadata": {
        "id": "Ik-Hd_WC892W"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # cs cv\n",
        "# overall_average_mean_average_precision_cs_cv = sum(global_average_mean_average_precision_cs_cv)/len(global_average_mean_average_precision_cs_cv)\n",
        "# print(overall_average_mean_average_precision_cs_cv)\n",
        "\n",
        "# overall_mean_average_recall_cs_cv = sum(global_mean_average_recall_cs_cv)/len(global_mean_average_recall_cs_cv)\n",
        "# print(overall_mean_average_recall_cs_cv)"
      ],
      "metadata": {
        "id": "LP499ZPM9AGB"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # cs tfidf\n",
        "# overall_average_mean_average_precision_cs_tfidf = sum(global_average_mean_average_precision_cs_tfidf)/len(global_average_mean_average_precision_cs_tfidf)\n",
        "# print(overall_average_mean_average_precision_cs_tfidf)\n",
        "\n",
        "# overall_mean_average_recall_cs_tfidf = sum(global_mean_average_recall_cs_tfidf)/len(global_mean_average_recall_cs_tfidf)\n",
        "# print(overall_mean_average_recall_cs_tfidf)"
      ],
      "metadata": {
        "id": "QM0hy0wi9C2r"
      },
      "execution_count": 123,
      "outputs": []
    }
  ]
}