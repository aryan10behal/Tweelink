{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_database_preprocessed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHDebklad8Hk",
        "outputId": "be1fffc1-9754-4001-91b1-a09b305a2d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhIMTgkbgfKQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from glob import glob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import num2words\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpus')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jF1ZvL9eEy9",
        "outputId": "3d748146-d662-4537-ed51-c37bea50903a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmmQqTnt3AF5",
        "outputId": "ba282273-114b-4368-ed69-d6aa7d88008f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = pd.read_csv('amisha.csv', on_bad_lines='skip', encoding='latin-1', engine='python')\n",
        "file2 = pd.read_csv(\"twitter_data_aryan.csv\", on_bad_lines='skip', encoding='latin-1', engine='python')\n",
        "file3 = pd.read_csv(\"twitter_data_Harman.csv\", on_bad_lines='skip', encoding='latin-1', engine='python') \n",
        "file4 = pd.read_csv(\"twitter_data_yash_bhargava.csv\", on_bad_lines='skip', encoding='latin-1', engine='python') \n",
        "file5 = pd.read_csv(\"twitter_data_yash_tanwar.csv\", on_bad_lines='skip', encoding='latin-1', engine='python') \n",
        "file6 = pd.read_csv(\"twitter_data_mayank.csv\", on_bad_lines='skip', encoding='latin-1', engine='python')"
      ],
      "metadata": {
        "id": "eqoRR-SKh-sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [file1, file2, file3, file4, file5, file6]\n",
        "final_pd = pd.concat(frames)"
      ],
      "metadata": {
        "id": "1YeyY9UOiWN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size = ', final_pd.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJO5vUednWuq",
        "outputId": "a2919f1b-ceb1-4d1e-9070-df04c1f2dfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size =  (274803, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping ALL duplicate values\n",
        "final_pd.drop_duplicates(subset =\"tweet\", keep = False, inplace = True)\n",
        "final_pd.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "MZGliNkPiyXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size = ', final_pd.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271mfCo8ngMU",
        "outputId": "2d740811-bb4b-446d-a5f9-7b91291285bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size =  (224213, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting to lowercase\n",
        "def to_lower_case(text):\n",
        "  text = text.lower()\n",
        "  return text\n",
        "\n",
        "#Substituting words with apostrophe with their possible base form\n",
        "def substitute_text(text):\n",
        "  text_list = []\n",
        "  substitutes = {\"aren't\": 'are not', \"can't\": 'cannot', \"couldn't\": 'could not', \"didn't\": 'did not', \"doesn't\": 'does not', \"don't\": 'do not', \"hadn't\": 'had not', \"hasn't\": 'has not', \"haven't\": 'have not', \"he'd\": 'he would', \"he'll\": 'he will', \"he's\": 'he is', \"i'd\": 'i would', \"i'll\": 'i will', \"i'm\": 'i am', \"isn't\": 'is not', \"it's\": 'it is', \"it'll\": 'it will', \"i've\": 'i have', \"let's\": 'let us', \"mightn't\": 'might not', \"mustn't\": 'must not',\"n't\": 'not', \"shan't\": 'shall not', \"she'd\": 'she would', \"she'll\": 'she will', \"she's\": 'she is', \"shouldn't\": 'should not', \"that's\": 'that is', \"there's\": 'there is', \"they'd\": 'they would', \"they'll\": 'they will', \"they're\": 'they are', \"they've\": 'they have', \"we'd\": 'we would', \"we're\": 'we are', \"weren't\": 'were not', \"we've\": 'we have', \"what'll\": 'what will', \"what're\": 'what are', \"what's\": 'what is', \"what've\": 'what have', \"where's\": 'where is', \"who'd\": 'who would', \"who'll\": 'who will', \"who're\": 'who are', \"who's\": 'who is', \"who've\": 'who have', \"won't\": 'will not', \"wouldn't\": 'would not', \"you'd\": 'you would', \"you'll\": 'you will', \"you're\": 'you are', \"you've\": 'you have', \"'re\": ' are', \"wasn't\": 'was not', \"we'll\": 'we will', \"'cause\": 'because', \"could've\": 'could have', \"how'd\": 'how did', \"how'd'y\": 'how do you', \"how'll\": 'how will', \"how's\": 'how is', \"I'd\": 'I would', \"I'd've\": 'I would have', \"I'll\": 'I will', \"I'll've\": 'I will have', \"I'm\": 'I am', \"I've\": 'I have', \"i'd've\": 'i would have', \"i'll've\": 'i will have', \"it'd\": 'it would', \"it'd've\": 'it would have', \"it'll've\": 'it will have', \"ma'am\": 'madam', \"mayn't\": 'may not', \"might've\": 'might have', \"mightn't've\": 'might not have', \"must've\": 'must have', \"mustn't've\": 'must not have', \"needn't\": 'need not', \"needn't've\": 'need not have', \"o'clock\": 'of the clock', \"oughtn't\": 'ought not', \"oughtn't've\": 'ought not have', \"sha'n't\": 'shall not', \"shan't've\": 'shall not have', \"she'd've\": 'she would have', \"she'll've\": 'she will have', \"should've\": 'should have', \"shouldn't've\": 'should not have', \"so've\": 'so have', \"so's\": 'so as', \"this's\": 'this is', \"that'd\": 'that would', \"that'd've\": 'that would have', \"there'd\": 'there would', \"there'd've\": 'there would have', \"here's\": 'here is', \"they'd've\": 'they would have', \"they'll've\": 'they will have', \"to've\": 'to have', \"we'd've\": 'we would have', \"we'll've\": 'we will have', \"what'll've\": 'what will have', \"when's\": 'when is', \"when've\": 'when have', \"where'd\": 'where did', \"where've\": 'where have', \"who'll've\": 'who will have', \"why's\": 'why is', \"why've\": 'why have', \"will've\": 'will have', \"won't've\": 'will not have', \"would've\": 'would have', \"wouldn't've\": 'would not have', \"y'all\": 'you all', \"y'all'd\": 'you all would', \"y'all'd've\": 'you all would have', \"y'all're\": 'you all are', \"y'all've\": 'you all have', \"you'd've\": 'you would have', \"you'll've\": 'you will have'}\n",
        "  text_tokenised = text.split()\n",
        "  for i in text_tokenised:\n",
        "    if(i in substitutes):\n",
        "      text_list.append(substitutes[i])\n",
        "    else:\n",
        "      text_list.append(i)\n",
        "  return ' '.join(text_list)\n",
        "\n",
        "#Removing punctuations\n",
        "def remove_punctuations(text):\n",
        "  punctuations = '''!()-[|]`{};:'\"\\,<>./?@#$=+%^&*_~'''\n",
        "  new_list = ['' if x in punctuations else x for x in text]\n",
        "  new_list_final = []\n",
        "  for token in new_list:\n",
        "    new_token=\"\"\n",
        "    for char in token:\n",
        "      if(char not in punctuations):\n",
        "        new_token+=char\n",
        "    if(len(new_token)!=0):\n",
        "      new_list_final.append(new_token)\n",
        "  return new_list_final\n",
        "\n",
        "#Removing stopwords\n",
        "def remove_stopwords(text):\n",
        "  stopword = stopwords.words('english')\n",
        "  new_list = [x for x in text if x not in stopword]\n",
        "  return new_list\n",
        "\n",
        "# #Converting number to words\n",
        "# def num_to_words(text):\n",
        "#   new_text = ' '.join([num2words.num2words(i) if i.isdigit() else i for i in text.split()])\n",
        "#   return new_text\n",
        "  \n",
        "# #Stemming\n",
        "# def stemming(text):\n",
        "#   stemmer = PorterStemmer()\n",
        "#   new_list = [stemmer.stem(x) for x in word_tokenize(text)]\n",
        "#   return ' '.join(new_list)\n",
        "\n",
        "#Tokenization\n",
        "def tokenization(text):\n",
        "  return word_tokenize(text)\n",
        "\n",
        "def lemmatization(text):\n",
        "  wordnet_lemmatizer = WordNetLemmatizer()\n",
        "  new_list = [wordnet_lemmatizer.lemmatize(x) for x in text]\n",
        "  return new_list\n"
      ],
      "metadata": {
        "id": "lRrtEdiQeLHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining all preprocessing steps together for a text\n",
        "def text_preprocess(text):\n",
        "  text = to_lower_case(text)\n",
        "  text = substitute_text(text)\n",
        "  text = tokenization(text)\n",
        "  text = remove_stopwords(text)\n",
        "  text = remove_punctuations(text)\n",
        "  text = [x.strip() for x in text if len(x.strip())]\n",
        "  text = lemmatization(text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "J_dnGd_jeORt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_date(text):\n",
        "  return text[:10]"
      ],
      "metadata": {
        "id": "ACo78n3dzTEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_date(\"2022-02-14 00:11:44+00:00\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdOS8DkKzUd0",
        "outputId": "bb663db1-49f9-4f8d-d84e-dc7ce891b5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocess(\"CommonSenseGunLaws,GunControlNow,GunSafes,GunSafety,GunRegistry,MSDStrong,EnoughIsEnough\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gs191t6gTwb",
        "outputId": "e72d05c0-c959-4bb9-8416-27a09ecd2e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['commonsensegunlaws',\n",
              " 'guncontrolnow',\n",
              " 'gunsafes',\n",
              " 'gunsafety',\n",
              " 'gunregistry',\n",
              " 'msdstrong',\n",
              " 'enoughisenough']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# headers\n",
        "print(final_pd.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-T7aqT5hEgn",
        "outputId": "3f397839-a7fc-4bb7-a1a7-7fb3c06bcc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               author id                 created_at geo country country_code  \\\n",
            "0           1952510090.0  2022-02-14 00:11:44+00:00                            \n",
            "1             20453105.0  2022-02-14 00:04:56+00:00                            \n",
            "2  1492660754998247424.0  2022-02-14 00:39:55+00:00                            \n",
            "3            117812637.0  2022-02-14 00:20:05+00:00                            \n",
            "4  1490044524604928000.0  2022-02-14 00:10:26+00:00                            \n",
            "\n",
            "  place_full_name place_name place_type                     id lang  ...  \\\n",
            "0                                        1493015060943454208.0   en  ...   \n",
            "1                                        1493013352938934272.0   en  ...   \n",
            "2                                        1493022155239534336.0   en  ...   \n",
            "3                                        1493017163485044736.0   en  ...   \n",
            "4                                        1493014734903382016.0   en  ...   \n",
            "\n",
            "  reply_count retweet_count               source  \\\n",
            "0         0.0           3.0  Twitter for Android   \n",
            "1         1.0           0.0  Twitter for Android   \n",
            "2         0.0           0.0  Twitter for Android   \n",
            "3         0.0           0.0   Twitter for iPhone   \n",
            "4         1.0           5.0   Twitter for iPhone   \n",
            "\n",
            "                                               tweet  \\\n",
            "0  ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...   \n",
            "1  It's too bad these guys are afraid of needles,...   \n",
            "2  Cowboy dressed as #Furries now available at th...   \n",
            "3  We blocked these trucks from entering the dntn...   \n",
            "4  Krista is very pleased with how the @RCMPONT r...   \n",
            "\n",
            "                                            hashtags sensitive  \\\n",
            "0  CommonSenseGunLaws,GunControlNow,GunSafes,GunS...     False   \n",
            "1          ClownConvoy,FreeDumbConvoy,OttawaOccupied     False   \n",
            "2                    Furries,RamRanch,OttawaOccupied     False   \n",
            "3                           Riverside,OttawaOccupied     False   \n",
            "4  FluTruxKlanGoHome,OttawaOccupied,kkkonvoy,Otta...     False   \n",
            "\n",
            "                      urls context_text context_probability context_type  \n",
            "0  https://t.co/LjkEup24Dk                              0.0               \n",
            "1  https://t.co/MmFzuFjIDR                              0.0               \n",
            "2  https://t.co/GBuBCUtpXe                              0.0               \n",
            "3  https://t.co/KzLkBZvjgD                              0.0               \n",
            "4  https://t.co/kAm5KNugdA                              0.0               \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating preprocessed data column\n",
        "final_pd['Preprocessed_Data'] = final_pd[\"tweet\"] + \" \"+ final_pd[\"hashtags\"] + \" \"+ final_pd[\"place_full_name\"] + \" \" + final_pd[\"context_text\"] "
      ],
      "metadata": {
        "id": "bZDgwIITrLFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pd['Preprocessed_Data'] = final_pd['Preprocessed_Data'].map(text_preprocess)"
      ],
      "metadata": {
        "id": "zuH0h-YZs3qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pd['Date_Only'] = final_pd['created_at'].map(extract_date)"
      ],
      "metadata": {
        "id": "pttzabSQysxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(final_pd[\"Preprocessed_Data\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evlpUKm9jx8X",
        "outputId": "d553513b-a030-48b2-888f-13a7c7d00dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_pd.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEzvnWRYavba",
        "outputId": "b485316b-f557-486f-b461-a2a865e91aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               author id                 created_at geo country country_code  \\\n",
            "0           1952510090.0  2022-02-14 00:11:44+00:00                            \n",
            "1             20453105.0  2022-02-14 00:04:56+00:00                            \n",
            "2  1492660754998247424.0  2022-02-14 00:39:55+00:00                            \n",
            "3            117812637.0  2022-02-14 00:20:05+00:00                            \n",
            "4  1490044524604928000.0  2022-02-14 00:10:26+00:00                            \n",
            "\n",
            "  place_full_name place_name place_type                     id lang  ...  \\\n",
            "0                                        1493015060943454208.0   en  ...   \n",
            "1                                        1493013352938934272.0   en  ...   \n",
            "2                                        1493022155239534336.0   en  ...   \n",
            "3                                        1493017163485044736.0   en  ...   \n",
            "4                                        1493014734903382016.0   en  ...   \n",
            "\n",
            "                source                                              tweet  \\\n",
            "0  Twitter for Android  ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...   \n",
            "1  Twitter for Android  It's too bad these guys are afraid of needles,...   \n",
            "2  Twitter for Android  Cowboy dressed as #Furries now available at th...   \n",
            "3   Twitter for iPhone  We blocked these trucks from entering the dntn...   \n",
            "4   Twitter for iPhone  Krista is very pleased with how the @RCMPONT r...   \n",
            "\n",
            "                                            hashtags sensitive  \\\n",
            "0  CommonSenseGunLaws,GunControlNow,GunSafes,GunS...     False   \n",
            "1          ClownConvoy,FreeDumbConvoy,OttawaOccupied     False   \n",
            "2                    Furries,RamRanch,OttawaOccupied     False   \n",
            "3                           Riverside,OttawaOccupied     False   \n",
            "4  FluTruxKlanGoHome,OttawaOccupied,kkkonvoy,Otta...     False   \n",
            "\n",
            "                      urls context_text context_probability context_type  \\\n",
            "0  https://t.co/LjkEup24Dk                              0.0                \n",
            "1  https://t.co/MmFzuFjIDR                              0.0                \n",
            "2  https://t.co/GBuBCUtpXe                              0.0                \n",
            "3  https://t.co/KzLkBZvjgD                              0.0                \n",
            "4  https://t.co/kAm5KNugdA                              0.0                \n",
            "\n",
            "                                   Preprocessed_Data   Date_Only  \n",
            "0  [ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸...  2022-02-14  \n",
            "1  [bad, guy, afraid, needle, twinrix, would, pre...  2022-02-14  \n",
            "2  [cowboy, dressed, furries, available, ramranch...  2022-02-14  \n",
            "3  [blocked, truck, entering, dntn, core, riversi...  2022-02-14  \n",
            "4  [krista, pleased, rcmpont, responded, maskless...  2022-02-14  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_pd[\"tweet\"].iloc[0])\n",
        "print(final_pd[\"hashtags\"].iloc[0])\n",
        "print(final_pd[\"Date_Only\"].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM9Pj9uBxd42",
        "outputId": "92ec2c37-673c-4f19-89fa-847174b3d70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ð¥ð¥ð¥ð¥ð¥ð¥ð¥â¤µï¸â¤µï¸â¤µï¸\n",
            "Instead of treating the symptoms or aftermath of gun violence, we must go after the means, supply chain, the guns! #CommonSenseGunLaws #GunControlNow #GunSafes #GunSafety #GunRegistry #MSDStrong #EnoughIsEnough https://t.co/LjkEup24Dk\n",
            "CommonSenseGunLaws,GunControlNow,GunSafes,GunSafety,GunRegistry,MSDStrong,EnoughIsEnough\n",
            "2022-02-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_pd[\"Preprocessed_Data\"].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXi3UP_DwkAr",
        "outputId": "7b68182a-25f1-4a2d-87b2-ebfbae31ae70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ð\\x9f\\x92¥ð\\x9f\\x92¥ð\\x9f\\x92¥ð\\x9f\\x92¥ð\\x9f\\x92¥ð\\x9f\\x92¥ð\\x9f\\x92¥â¤µï¸\\x8fâ¤µï¸\\x8fâ¤µï¸\\x8f', 'instead', 'treating', 'symptom', 'aftermath', 'gun', 'violence', 'must', 'go', 'mean', 'supply', 'chain', 'gun', 'commonsensegunlaws', 'guncontrolnow', 'gunsafes', 'gunsafety', 'gunregistry', 'msdstrong', 'enoughisenough', 'http', 'tcoljkeup24dk', 'commonsensegunlaws', 'guncontrolnow', 'gunsafes', 'gunsafety', 'gunregistry', 'msdstrong', 'enoughisenough']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"/content/drive/MyDrive/IR/twitter_base_preprocessed.pkl\", \"wb\")\n",
        "pickle.dump(final_pd, file1)\n",
        "file1.close()"
      ],
      "metadata": {
        "id": "vVpAH4Z5yDI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pd.to_csv('twitter_base_final_tweet_dataset.csv')"
      ],
      "metadata": {
        "id": "burueaBmiltG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}